---
title: ""
output:
  # html_document
  bookdown::word_document2:
    reference_docx: mytemplate.docx
    keep_text: true
---

```{r setup, include=FALSE, fig.align = 'center'}

knitr::opts_chunk$set(echo = FALSE, eval = T, message = F, warning = F, fig.align = 'center', cache.lazy = F)

library(here) #v1.0.1
library(dplyr) #v1.0.5
library(nimble) #v0.12.1
library(coda)
library(ggh4x)
library(readr)
library(knitr)
library(Hmisc)
library(stringr)
library(cowplot)
library(captioner)

#functions to use for calling figures/tables
figs <- captioner(prefix = "Figure")
tbls <- captioner(prefix = "Table")

source(here::here('scripts', 'PlotTheme.R'))

```

```{r scenarios and convergence}

sc <- c(1:45)

scenarios <- data.frame(scenario = c(sc),
                        survey_freq = c(rep(1,15), rep(2,15), rep(3,15)),
                        detection = c(rep(c('Low', 'Low', 'Low', 'Low', 'Low',
                                            'Med', 'Med', 'Med', 'Med', 'Med', 
                                            'High', 'High', 'High', 'High', 'High'), 3)),
                        N = c(rep(c(50,75,100,150,200), 9)))

med.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'median', all.files = FALSE, full.names = F)


converged <- data.frame()
for (f in 1:length(med.files)) {

rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge','sims', 
                                                     med.files[f]))[,'max_rhat']) %>%
  transform(scenario = parse_number(gsub('S.', '', med.files[f]))) %>%
  transform(batch = str_sub(med.files[f], -6,-5)) %>%
  transform(rhat = as.numeric(rhat))

converged <- rbind(converged, rhats)

}

tot_runs <- converged %>%
  filter(!is.na(rhat)) %>%
  group_by(scenario, batch) %>%
  dplyr::summarize(tot = n())

prop_conv <- converged %>%
  filter(rhat<1.10) %>%
  group_by(scenario) %>%
  dplyr::summarize(conv = n()) %>%
  merge(tot_runs, by = 'scenario', all = T) %>%
  transform(prop_conv = round(conv/tot,2)) %>%
  dplyr::select(scenario, tot, prop_conv)

scenarios_tab <- scenarios %>%
  merge(prop_conv, by = 'scenario') %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial')))

# kable(scenarios_tab)

#for figure legends
phi_pars <- c('phi[P]','phi[1]', 'phi[2]', 'phi[J]', 'phi[A]')
p_pars <- c('p[1]', 'p[2]', 'p[J]', 'p[A]') 
freq_labels <- c('1' = 'Annual', '2' = 'Biennial', '3' = 'Triennial')
occ_labels <- c('5' = '5 yrs', '10' = '10 yrs', '15' = '15 yrs', '20' = '20 yrs')

```

```{r cv}

#load in results for 10-yr study horizon
cv.files7 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv7', all.files = FALSE, full.names = F)

cv.files8 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv8', all.files = FALSE, full.names = F)

cv.files9 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv9', all.files = FALSE, full.names = F)

cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files12 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv12', all.files = FALSE, full.names = F)

cv.files <- c(cv.files7, cv.files8, cv.files9, cv.files10, cv.files11, cv.files12)


cv <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv <- rbind(cv, temp)

} #rds file

cv <- cv %>%
  filter(rhat < 1.1) 

mean.cv <- data.frame(cv) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

mean.cv.thresh <- data.frame(cv) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

#load in results from 20-yr study and merge
cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files14 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv14', all.files = FALSE, full.names = F)

cv.files15 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv15', all.files = FALSE, full.names = F)

cv.files18 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv18', all.files = FALSE, full.names = F)

cv.files19 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv19', all.files = FALSE, full.names = F)

cv.files22 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'),
                         pattern = 'cv22', all.files = FALSE, full.names = F)

cv.files23 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv23', all.files = FALSE, full.names = F)

cv.files26 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv26', all.files = FALSE, full.names = F)

cv.files27 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv27', all.files = FALSE, full.names = F)

cv.files30 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv30', all.files = FALSE, full.names = F)

cv.files31 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv31', all.files = FALSE, full.names = F)


cv.files <- c(cv.files10, cv.files11, cv.files14, cv.files15, cv.files18, cv.files19,
              cv.files22, cv.files23, cv.files26, cv.files27, cv.files30, cv.files31)

cv.20 <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv.20 <- rbind(cv.20, temp)

} #rds file

cv.20 <- cv.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) #%>%
  # bind_rows(cv)

mean.cv.20 <- data.frame(cv.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 20) %>%
  bind_rows(mean.cv)

### figures

## continuous dotplots
dotplot_dat_mean <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_up <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(upper = quantile(value, probs = 0.975), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_low <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(lower = quantile(value, probs = 0.025), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat <- dotplot_dat_mean %>%
  merge(dotplot_dat_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_dat_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Marking frequency', samp_size = 'Study horizon and cohort size',
            det = 'Detection')

#study horizon
cv_cont_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_errorbar(aes(ymin = lower, ymax = upper, x = survey_freq), width = 0.1) +
  xlab('Marking frequency') + ylab('Coefficient of Variation (CV)') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

#same as above, dif shapes too
cv_cont_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value, col = factor(variable), 
           shape = factor(variable), group = variable),
                  position = position_dodge(width = 2)) +
  geom_point() + geom_line() +
  geom_errorbar(aes(ymin = lower, ymax = upper, x = survey_freq), width = 0.1) +
  xlab('Marking frequency') + ylab('Coefficient of Variation (CV)') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

##threshold approach

#dotplot 
dotplot_dat <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  transform(value_cat = value<0.125) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Marking frequency', samp_size = 'Study horizon and cohort size',
            det = 'Detection')

#no quantile error bars on yes/no 
cv_thresh_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value_cat, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Marking frequency') + ylab('Probability of CV < 0.125') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

###appendix figures -- none unless want all sample sizes shown

##continuous cv
plot_dat <- mean.cv.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_heat_cont <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "CV",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
        strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 11),
        axis.text = element_text(size = 11),
        strip.text = element_text(size = 11)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##threshold

#heatmaps
mean.cv.thresh.20 <- data.frame(cv %>% transform(length = 10)) %>% 
  bind_rows(cv.20 %>% transform(length = 20)) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), 
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size')

plot_dat <- mean.cv.thresh.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_thresh_heat <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') + ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of \n CV < 0.125",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'right',
        strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 11),
        axis.text = element_text(size = 11),
        strip.text = element_text(size = 11)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


```


```{r collapsed cv}

#mean.cri.20 contains the mean probability (across simulations) where the cv < 0.125.

#values for the scenario with the "least" amount of contributing information
#i.e., triennial sampling, N = 50, 10 years, low detection (scenario 31)

cv_least_info <- mean.cv.thresh.20 %>% transform(samp_size = 'Sample size') %>%
  dplyr::select(!survey_frequency) %>%
  filter(detection == 'Low' & length %in% c(10,20) &
           survey_freq == 3 & N %in% c(50, 100, 200)) %>%
  dplyr::select(c(variable, N, value_cat, length)) %>%
  dplyr::rename(min_val = value_cat)

cv_delta <- mean.cv.thresh.20 %>% filter(length %in% c(10,20)) %>%
    filter(N %in% c(50, 100, 200)) %>% 
  merge(cv_least_info, by = c('variable', 'N', 'length')) %>%
  transform(delta = value_cat-min_val) %>%
  transform(det_cat = as.numeric(factor(detection)),
            N_cat = as.numeric(factor(N))) %>%
  # filter(variable == 'phiP') %>%
  # filter(variable %in% c('phiP', 'phi1')) %>%
  transform(survey_cat = 4-as.numeric(factor(survey_freq))) %>%
  transform(step = N_cat + survey_cat + det_cat) %>%
  transform(step = ifelse(detection == 'Low' & survey_freq == 3, 0, step))

cv_delta_steps <- cv_delta %>% 
  # filter(N == 50 & variable == 'phiP') %>%
    # filter(variable %in% c('phiP', 'phi1')) %>%
  transform(category = ifelse(step == 0, 'Baseline', 
                  ifelse(det_cat > 1 & survey_cat == 1, 'Detection only',
                  ifelse(survey_cat > 1 & det_cat == 1, 'Frequency only', 'Detection & frequency')))) %>%
  transform(step = ifelse(step == 0, 0,
                          ifelse(det_cat == 1 & survey_cat == 1, NA,
                            ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 1 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 1, 2, 
                            ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 2 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 2, 2, 
                            ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 3 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 3, 2, 
                            ifelse(det_cat == 1 & survey_cat == 1, NA, NA)))))))))) 

scenario_fill_cv <- expand.grid(step = 0,
              length = c(10,20),
              N = c(50, 100, 200),
              category = c('Detection only', 'Frequency only', 
                                         'Detection & frequency')) %>%
  merge(cv_delta_steps %>% dplyr::select(length, min_val, category, variable, N), 
        by = c('category', 'N', 'length')) %>% 
  distinct() %>%
  dplyr::rename(value_cat = min_val)
                            
effort_cv_dat <- cv_delta_steps %>%
  dplyr::select(category, N, length, step, value_cat, variable) %>%
  bind_rows(scenario_fill_cv) %>%
  filter(category != 'Baseline') %>%
  transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Marking frequency only', 'Detection & marking frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High')))

#probability of detecting change.... 
effort_cv_dot <- ggplot(effort_cv_dat %>% filter(!is.na(step)) %>%
         transform(samp_size = 'Sample size & study length') %>%
         transform(length = factor(length, labels = c('10 yrs', '20 yrs'))) %>%
           transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                                       labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))), 
       aes(factor(step), value_cat, group = category, col = category)) +
  geom_point() +
  geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  facet_nested(variable~samp_size+length+N) +
  xlab('Survey effort (detection + marking frequency)') + 
  ylab('Probability of CV < 0.125') +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "white", color = "black"),
        strip.text = element_text(size = 11),
        legend.text = element_text(size = 10, vjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        legend.title = element_text(vjust = 0.8, size = 11)) +
    scale_color_manual(values = rainbow2[-c(1,4,6)], name = '')

```


```{r detecting change}

#load in results from 10-yr
cri.scenarios <- c('dec_little', 'dec_big')
append <- c(5,10)

cri.all <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -5,-5)) %>%
  transform(length = append[a]) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all <- rbind(cri, cri.all)

} #rds file
} #j


mean.cri <- data.frame(cri.all) %>%
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size') 

#load in results from 20-yr
cri.all.20 <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop', 
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -6,-5)) %>%
  transform(length = append[a]+10) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all.20 <- rbind(cri, cri.all.20)

} #rds file
} #j

mean.cri.20 <- data.frame(cri.all.20) %>%
  #are these just all the unfinished/unfilled sim dataframe rows? 
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  bind_rows(mean.cri)

#plots

#dotplot

dotplot_dat <- cri.all.20 %>% filter(length == 20) %>% 
  bind_rows(cri.all %>% filter(length == 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N, threshold) %>%
    dplyr::summarize(value = mean(value, na.rm = T), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Marking frequency', samp_size = 'Study horizon and cohort size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

cri_dot_big <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) & length %in% c(10,20)
                               &  threshold == 'dec_big'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Marking frequency') + ylab('Probability of detecting larger difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

cri_dot_small <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) & length %in% c(10,20)
                               &  threshold == 'dec_little'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Marking frequency') + ylab('Probability of detecting small difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

#appendix figures

#all facets
plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & change size', 
            samp_size = 'Sample size & study length')

#all facets continuous
cri_all_cont_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "white", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#all facets categorical
cri_all_cat_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "white", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting difference in survival",
                    # values = c('firebrick3', 'orange', 'steelblue2'))
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))

#fewer facets
 plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable) & length %in% c(10,20)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size')
 
#big decrease in survival 
cri_big_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')), 
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of detecting difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "white", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) 

#categorical, small decrease
cri_big_cat_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')),
       aes(x = factor(detection), y = variable, fill = value_cat), alpha = 0.3) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "white", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting small change",
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))

#more years (5, 10, 15, 20)
dotplot_dat <- cri.all.20 %>%  
  bind_rows(cri.all) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N, threshold) %>%
    dplyr::summarize(value = mean(value, na.rm = T), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(survey_frequency = 'Marking frequency', samp_size = 'Study horizon and cohort size',
            det = 'Detection and threshold') %>%
  #filter out detection params
  filter(!is.na(variable))

cri_dot_app <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Marking frequency') + ylab('Probability of detecting difference in survival') +
  facet_nested(det + detection + threshold ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

```

```{r collapsed detecting change}

#mean.cri.20 contains the mean probability (across simulations) where the cv < 0.125.

#values for the scenario with the "least" amount of contributing information
#i.e., triennial sampling, N = 50, 10 years, low detection (scenario 31)

cri_least_info <- mean.cri.20 %>% transform(samp_size = 'Sample size') %>%
  dplyr::select(!survey_frequency) %>%
  filter(detection == 'Low' & length %in% c(10,20) &
           survey_freq == 3 & N %in% c(50, 100, 200)) %>%
  dplyr::select(c(variable, N, value, length, threshold)) %>%
  dplyr::rename(min_val = value)

cri_delta <- mean.cri.20 %>% filter(length %in% c(10,20)) %>%
    filter(N %in% c(50, 100, 200)) %>% 
  merge(cri_least_info, by = c('variable', 'N', 'length', 'threshold')) %>%
  transform(delta = value-min_val) %>%
  transform(det_cat = as.numeric(factor(detection)),
            N_cat = as.numeric(factor(N))) %>%
  # filter(variable == 'phiP') %>%
  # filter(variable %in% c('phiP', 'phi1')) %>%
  transform(survey_cat = 4-as.numeric(factor(survey_freq))) %>%
  transform(step = N_cat + survey_cat + det_cat) %>%
  transform(step = ifelse(detection == 'Low' & survey_freq == 3, 0, step))

cri_delta_steps <- cri_delta %>% 
  # filter(N == 50 & variable == 'phiP') %>%
    # filter(variable %in% c('phiP', 'phi1')) %>%
  transform(category = ifelse(step == 0, 'Baseline', 
                  ifelse(det_cat > 1 & survey_cat == 1, 'Detection only',
                  ifelse(survey_cat > 1 & det_cat == 1, 'Frequency only', 'Detection & frequency')))) %>%
  transform(step = ifelse(step == 0, 0,
                          ifelse(det_cat == 1 & survey_cat == 1, NA,
                            ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 1 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 1, 2, 
                            ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 2 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 2, 2, 
                            ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 3 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 3, 2, 
                            ifelse(det_cat == 1 & survey_cat == 1, NA, NA)))))))))) 

scenario_fill_cri <- expand.grid(step = 0,
              length = c(10,20),
              threshold = c('dec_little', 'dec_big'),
              N = c(50, 100, 200),
              category = c('Detection only', 'Frequency only', 
                                         'Detection & frequency')) %>%
  merge(cri_delta_steps %>% dplyr::select(length, threshold, min_val, category, variable, N), 
        by = c('category', 'N', 'length', 'threshold')) %>% 
  distinct() %>%
  dplyr::rename(value = min_val)
                            
effort_dat <- cri_delta_steps %>%
  dplyr::select(category, N, length, threshold, step, value, variable) %>%
  bind_rows(scenario_fill_cri) %>%
  filter(category != 'Baseline') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(threshold_name = factor(threshold, levels = c('dec_little', 'dec_big'), 
                                    labels = c('Small difference', 'Large difference'))) %>%
  transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Marking frequency only', 'Detection & marking frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High')))

#probability of detecting change.... 
effort_dot <- ggplot(effort_dat %>% filter(!is.na(step)) %>% filter(variable == 'Pup') %>%
         transform(samp_size = 'Sample size & study length') %>%
         transform(length = factor(length, labels = c('10 yrs', '20 yrs'))), 
       aes(factor(step), value, group = category, col = category)) +
  geom_point() +
  geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  facet_nested(threshold_name~samp_size+length+N) +
  xlab('Survey effort (detection + marking frequency)') + 
  ylab('Probability of detecting difference in pup survival') +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        axis.text.x = element_text(angle = 90, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_color_manual(values = rainbow2[-c(1,4,6)], name = '')


text_dat <- cri_delta_steps %>%
  distinct(category, det_cat, survey_cat, step) %>%
  transform(inc = ifelse(det_cat == 2 & survey_cat == 3 | det_cat == 3 & survey_cat == 2, 'n', 'y')) %>%
  filter(inc == 'y') %>%
  dplyr::select(-inc) %>%
   transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Marking frequency only', 'Detection & marking frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High'))) %>%
  transform(det_cat = factor(det_cat, labels = c('Low', 'Medium', 'High')),
            survey_cat = factor(survey_cat, labels = c('Triennial', 'Biennial', 'Annual')))

effort_grid <- ggplot(text_dat %>% filter(category != 'Baseline'), aes(det_cat, survey_cat, fill = category)) +
  geom_tile(data =  text_dat %>% filter(category != 'Baseline'), 
            color = "white", lwd = 1.5) +
  geom_tile(data = text_dat %>% filter(category == 'Baseline'), 
            fill = 'slateblue4', color = "white", lwd = 1.5, show.legend = F) +
  geom_text(aes(label = step), fontface = 'bold') +
  # geom_text(data = text_dat %>% filter(category == 'Baseline'),
  #           aes(label = step), show.legend = F) +
  annotate('text', x = 1, y = 1, label = 'Low', fontface = 'bold') +
  ylab('Marking frequency') + xlab('Detection') +
  theme_bw() +
  theme(legend.position = 'top',
        legend.key.size = unit(0.35, "cm"),
        panel.grid.major = element_blank(),
        axis.text.y = element_text(angle = 90, hjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        axis.title.y = element_text(vjust = 2)) +
  scale_fill_manual(values = c(rainbow2[-c(1,4,6)]), name = '')

effort_plot <- plot_grid(effort_grid, effort_dot, labels = c('(a)', '(b)'), rel_widths = c(0.75, 1.1))

#appendix - all ages
effort_dot_app <- ggplot(effort_dat %>% filter(!is.na(step)) %>% 
         transform(samp_size = 'Sample size & study length') %>%
         transform(length = factor(length, labels = c('10 yrs', '20 yrs'))), 
       aes(factor(step), value, group = category, col = category)) +
  geom_point() +
  geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  facet_nested(threshold_name+variable~samp_size+length+N) +
  xlab('Survey effort (detection + marking frequency)') + 
  ylab('Probability of detecting difference in survival') +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_color_manual(values = rainbow2[-c(1,4,6)], name = '')

```

```{r relative bias}

bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias <- rbind(rel.bias, temp)

} #rds file

rel.bias <- rel.bias %>%
  filter(rhat < 1.1) %>%
  transform(length = 10)

mean.rel.bias <- data.frame(rel.bias) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)


bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias.20 <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias.20 <- rbind(rel.bias.20, temp)

} #rds file

rel.bias.20 <- rel.bias.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20)

mean.rel.bias.20 <- data.frame(rel.bias.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rel.bias) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and cohort size') 

#figures
#heatmaps
plot_dat <- mean.rel.bias.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) 


bias_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
       aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Marking frequency') + ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(length = occ_labels),
             scales = 'free_x') +
  scale_fill_gradient2(name = "Relative bias (%)",
                      mid = "#FFFFFF", low = "deepskyblue1", high = "red2", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#dotplots
dotplot_mean <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value)*100, .groups = 'keep') 

dotplot_low <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(lower = quantile(value*100, probs = 0.025), .groups = 'keep')

dotplot_up <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(upper = quantile(value*100, probs = 0.975), .groups = 'keep')

dotplot_dat <- dotplot_mean %>% 
  merge(dotplot_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and cohort size') %>%
  #filter out detection params
  filter(!is.na(variable))

bias_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  # geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 0), linetype = 'dotted') +
  xlab('Marking frequency') + ylab('Mean relative bias (%)') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +

  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')


```

```{r RMSE}

rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse <- rbind(rmse, temp)

} #rds file

rmse <- rmse %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 10)

mean.rmse <- data.frame(rmse) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Marking frequency & study length', 
            samp_size = 'Sample size') %>%
  transform(length = 10) 


rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse.20 <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse.20 <- rbind(rmse.20, temp)

} #rds file

rmse.20 <- rmse.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) 

mean.rmse.20 <- data.frame(rmse.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rmse) %>%
  transform(survey_frequency = 'Marking frequency & study length', 
            samp_size = 'Study horizon and cohort size', det = 'Detection') %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial')))


#plots
plot_dat <- mean.rmse.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

rmse_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
                    aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Marking frequency') +
  ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "RMSE",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "white", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##dot plots
dotplot_dat <- rmse.20 %>% transform(length = 20) %>% 
  bind_rows(rmse %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  # dplyr::summarize(value = mean(value),
  #                  lower = quantile(value, probs = 0.025),
  #                  upper = quantile(value, probs = 0.975),
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Marking frequency', samp_size = 'Study horizon and cohort size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

rmse_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  xlab('Marking frequency') + ylab('RMSE') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rev(rainbow2[-c(1,4,6)]), name = 'Age group')

```

(Placeholder) Title: Optimizing mark-resight survey design for demographic estimation  

Target journal: Journal of Wildlife Management; Marine Mammal Science  

Authors: Amanda J. Warlick$^1$, Brian Fadely$^2$, Peter Mahony$^2$, Sharon Melin$^2$, Tom Gelatt$^2$, Kim Raum-Suryan$^3$, Sarah J. Converse$^4$  

1. Cooperative Institute for Climate, Ocean, and Ecosystem Studies, University of Washington, Seattle, WA  

2. Marine Mammal Laboratory, Alaska Fisheries Science Center, National Marine Fisheries Service, Seattle, WA 

3. National Marine Fisheries Service, Protected Resources Division Alaska Regional Office, Seattle, WA

4. U.S. Geological Survey, Washington Cooperative Fish and Wildlife Research Unit, School of Aquatic and Fishery Sciences & School of Environmental and Forest Sciences, University of Washington, Seattle, WA  


### Abstract  

*Keywords*: mark-recapture survey, survey design, demography, Bayesian model, endangered species, Steller sea lion

### Introduction    

Knowledge about vital rates, population dynamics, and trends in abundance are essential for wildlife conservation and management. However, this information can be difficult to obtain at the level of precision that is useful for answering pressing management questions or developing meaningful and achievable conservation targets. For a depleted or declining population, the ideal survey design would be one that would be able to facilitate detecting a change in population status most expediently. However, funding limitations in natural resource and wildlife fields dictate that the ideal survey design be both effective and efficient, delivering the quickest (and most precise) possible answers at the lowest cost (Field et al. 2005, Field et al. 2007, Sims et al. 2008, Reynolds et al. 2011). In addition to being costly, it may also be invasive, disruptive, or logistically challenging to obtain data at the level of precision that is required to address monitoring objectives, particularly for small, declining, or remote populations. It is therefore critically important to develop wildlife monitoring programs that optimize the trade-offs between survey effort (and the resulting quality of information obtained) and survey cost for a given wildlife species, population, or habitat location of interest. Unfortunately, statistical power analyses or simulation analyses that inform choices about survey design are seldom conducted before monitoring programs are implemented (Legg & Nagy 2006, Lindenmayer & Likens 2009), potentially leading to wasted funding resources, lost opportunities for implementing adaptive management, reduced public trust, and  underperforming monitoring programs. 

Wildlife monitoring programs are often focused on tracking trends in abundance or vital rates that can inform status assessments and predictions of extinction risk (Campbell et al. 2002), track progress toward recovery goals or response to management actions (Nichols & Williams 2006, Johnston et al. 2015), or provide insight about population-level effects of environmental variability or anthropogenic stressors. Without sufficiently precise population monitoring data, resource managers could fail to detect that an allowable take level was exceeded for a threatened species, or overly restrict other resource uses if a mortality or take level was overestimated. However, the level of precision that is required to adequately inform these types of diverse monitoring objectives varies across habitats, species density, range extent, and management goals (Kristensen & Kovach 2018). For example, a higher level of precision and lower bias may be required to track the fate of a species reintroduction relative to the precision needed to detect a response to a habitat restoration intervention. When monitoring plans fail to meet these kinds of monitoring objectives, practitioners risk incorrectly declaring that a species or population does not meet an established criteria for management intervention, or conversely investing in developing additional mitigation measures that were not in fact warranted. In these contexts, imperfect detection during observations of complex ecological processes leads to varying degrees of uncertainty about the underlying processes (i.e., vital rates, environmental effects) or quantities (i.e., abundance, trends) of interest. This uncertainty (i.e., level of precision or bias in parameter estimates) is largely determined by survey effort, which often comprises multiple factors, including but not limited to the number of surveyed sites, the number of repeat surveys, the number of surveyed or marked individuals, and the duration of the study. All of these features have distinct advantages and cost profiles that are entirely dependent on the context of the study, including the life history characteristics of the species, the habitat, the conservation status, and monitoring objectives (Taylor et al. 2007), and therefore should be evaluated on an individul basis. 

Despite the importance of developing effective and efficient monitoring plans, numerous barriers often prevent wildlife practitioners from rigorously and statistically examining the trade-offs between survey effort, data quality, monitoring objectives, and costs prior to initiating a monitoring program (though see Peel et al. 2015). These barriers can arise from institutional, logistical, or even ecological situations. First, funding for wildlife monitoring programs often fluctuates over time (due to political regimes or change in a population's conservation status) and allocations may not come at predictable intervals or in sufficient amounts to afford additional time for simulation analyses to inform survey design. Additionally, monitoring costs may be difficult to quantify in such a way as to directly relate to demographic estimation (e.g., costs are more easily aggregated per field technician or per survey trip as opposed to being able to apportion costs per individual animal marked, nest surveyed, number of observation days, etc.). Monitoring costs may also be unpredictable due to logistical challenges of safely and consistently surveying dynamic environments or remote locations. Second, expertise to conduct such analyses may also be lacking. Third, poorly defined monitoring objectives that lack specific quantitative metrics makes conducting pre-survey design studies challenging, as there may not be a specified quantity of interest to "optimize". Nebulous monitoring objectives often perpetuate ongoing "surveillance" monitoring, which certainly can lead to improved insights about species and ecological processes, but is likely not the most efficient use of resources (Nichols & Williams 2006). These situations can arise when risk tolerances for making incorrect conservation decisions is difficult to elicit or quantify across diverse stakeholders. Due to these and other barriers and constraints, simulation studies are most often conducted *post-hoc* to validate model results by confirming that the survey protocol used for a given study generally produces asymptotically unbiased estimates or achieves a reasonable level of precision (Sun et al. 2014, Wilton et al. 2014, Lyons et al. 2015, Yackulic et al. 2015, Himes Boor et al. 2023). 

Designing an effective and efficient monitoring program for Steller sea lions (*Eumetopias jubatus*) is foundational for ongoing efforts to understand drivers of population dynamics in a cost effective way that maximizes the utility of limited available resources. Steller sea lion abundance declined considerably throughout the 1970-80s's, leading the species to be listed as Threatened under the Endangered Species Act (ESA). The species was subsequently divided into eastern and western distinct population segments (eDPS and wDPS, respectively). The eDPS (ranging from northern California into southeast Alaska) recovered and was delisted in 2013 while the wDPS (ranging from the Gulf of Alaska across the Aleutian Islands into Russia) maintains an Endangered status as abundance in certain rookeries has continued to decline for unknown reasons. Efforts to design a comprehensive monitoring program is complicated by the diverse landscapes, varying rookery breeding population sizes, and abundance trends across the species range. In this study, we present a simulation analysis examining parameter precision and the ability to detect a change in survival probabilities estimated using a mark-resight model framework across a range of survey features, including the size of the marked population, marking frequency, detection probability, and study length.  

Though the aim of this work was to inform the design of ongoing and future monitoring for Steller sea lions, the concepts and framework apply to other species or populations where mark-resight data are collected for the purpose of understanding demographic trends. Despite the challenges of conducting pre-survey studies to ensure that a given survey design will produce demographic estimates of sufficient precision at the lowest cost, not doing so risks wasting resources and/or not obtaining information critical for conservation decisions. Optimizing resource allocation in monitoring programs is particularly important for species where conservation status (and therefore monitoring needs and objectives) differs throughout its geographic range. Developing effective and efficient monitoring programs may become increasingly important and likewise increasingly challenging if funding levels for wildlife conservation and management remain constant or dwindle while the need for additional monitoring increases due to anticipated climate change and ever expanding anthropogenic uses of terrestrial and marine environments. The simulation framework and results presented here are useful across diverse applications and could assist natural resource managers in planning and executing effective monitoring programs that address pressing and emerging conservation questions. 

### Methods  

#### Study system  
Though this is a prospective study to inform a future monitoring program, we provide a brief summary of historical mark-resight survey effort across the Steller sea lion range to contextualize model results, evaluate the potential for achieving precision targets with available mark-resight data, and make future recommendations. In the eDPS where trends are stable or increasing, monitoring priorities include detecting trends in survival and evaluating the effects of environmental conditions on demography. From 2001-2015, eight cohorts of 150-200 sea lions have been marked and released biennially and resighted annually up through 2018. In the wDPS, mark-resight effort has been variable across the Gulf of Alaska and Aleutian Islands management subregions and monitoring priorities include identifying stressors that could be limiting recovery. East of Samalga Pass where population trends are stable or increasing, 3-6 cohorts ranging from approximately 100 to 200 sea lions have been marked and released biennially or triennially in three subregions and resighted nearly annually. West of Samalga Pass where populations are smaller and trends are decreasing, 3-4 cohorts of approximately 50 sea lions have been marked and released biennially since 2011 and resighted nearly annually. 

#### Data simulation and model description    
Mark-resight data were simulated over 10- and 20-year study horizons based on basic sea lion life history characteristics. Age class-specific survival and detection probabilities used as data-generating "true" values were based on empirical estimates from individuals branded, released, and resighted in the eastern DPS from 2001-2018. Temporal variance in survival probabilities was simulated based on the mean and standard deviation of age class-specific empirical estimates. Detection probabilities were assumed constant for each age class over the study period. Simulated data were fit to a Cormack Jolly Seber (Cormack 1964, Jolly 1965, Seber 1965) mark-resight model framework to estimate survival of five age classes (pups, age-1, age-2, juveniles (ages 3-4), and adults 5$^+$) with true ecological states defined by an individual's age. The state process model,

\begin{equation}
z_{i,t} | z_{i,t-1} \sim ~ \text{categorical}(\Omega_{z_{i,t-1},i,t-1}) 
\end{equation}

describes the state *z* of individual *i* at occasion *t*, conditional on the individual’s state at the previous occasion, modeled as categorically distributed according to transition array $\Omega$, which is composed of age group-specific survival probabilities ($\phi_\text{i,t}$). Fecundity was not of interest in this analysis and was therefore not incorporated into study design. Temporal variance in survival probabilities was modeled using penalized complexity priors (Simpson et al. 2017, van Erp et al. 2019), where for demographic rate parameter $\gamma$, 

\begin{equation}
\text{logit}(\gamma_\text{a,t}) = \mu_\text{a}^{\gamma} + \epsilon_\text{a,t}^{\gamma}   
\end{equation}

\begin{equation}
\epsilon_\text{a,t}^{\gamma} \sim \text{normal}(0, \sigma_\epsilon)
\end{equation}

\begin{equation}
\sigma_\epsilon \sim \text{exponential}(1) 
\end{equation}

where $\mu_\text{a}^{\gamma}$ is an age (*a*)-specific intercept estimated with back-transformed uninformative priors U(0,1) on the logit scale. $\epsilon_\text{a,t}^{\gamma}$ is an annual (*t*) random effect estimated with a normal distribution with mean zero and standard deviation estimated with a fixed shrinkage rate of exponential(1). This approach reduces the coefficient $\epsilon_\text{a,t}$ toward zero in the absence of strong support for an effect and can improve parameter estimability (Simpson et al. 2017).  

The observation process model included age class-specific observations of individuals based on detection probabilities that were assumed to be constant over the study period:

\begin{equation}
y_{i,t} | z_{i,t} \sim ~ \text{categorical}(\Theta_{z_{i,t} i,t})  
\end{equation}

where observations $y_\text{i,t}$ conditional on the true state $z_\text{i,t}$ are categorically distributed with probability array $\Theta$, which is composed of an individual's detection probability at time *t*, $p_\text{i,t}$. The typical set of mark-recapture model assumptions applied, where it was assumed that branding did not affect detection probability, that survival of individuals was independent, there were no identification errors, mortality during the sampling season was negligible, and that there was no unmodeled heterogeneity in survival and detection probabilities.
 
#### Simulation scenarios  
The above model was fit across 90 scenarios composed of all combinations of branding cohort sizes (N = 50, 75, 100, 150, 200), branding frequency (annual, biennial, triennial), study horizon (10 years versus 20 years), and detection rates (low, medium, high). Detection rates varied by age group, with low and high levels were set at +/- 20% of the age-specific empirical estimates (e.g., detection rate levels were 0.48, 0.6, 0.72 for age-1:2; 0.56, 0.7, 0.84 for juveniles; and 0.64, 0.8, 0.96 for adults). Resighting effort was assumed to occur annually regardless of branding schedule due to the increasing feasibility and use of remote cameras for this and other wildlife populations (Burton et al. 2015). 

As we were not able to quantify the monetary costs of survey effort per individual sea lion branded or resighted to develop a robust cost-benefit optimization scheme across all survey features, we also examined model performance across a “survey effort” metric (specific combinations of increasing branding frequency, detection probabilities, or both) to highlight which might yield the best model performance. The levels of this survey effort metric were “low” (triennial branding and low detection probabilities), “medium” representing one step of increased effort (biennial branding with low detection, medium detection with triennial branding, or medium detection and biennial branding), and “high” representing two steps of increased effort (annual branding and low detection, high detection and triennial branding, or annual branding and high detection). Annual branding may be unrealistic at most rookeries for Steller sea lions (disturbance and MMPA permit limitations, cost and logistics of surveying remote rookeries, etc.), but is included here as a point of comparison to the other branding frequency schedules and because it may likely be of interest to other wildlife populations or circumstances. Additionally, certain comparisons in the results section are highlighted based on the fact that branding cohort size may not be a survey feature that practitioners can easily modify (rookery size, number of consecutive visits to rookery, etc.). 
 
#### Model performance and fitting     
We assessed model performance across four metrics: coefficient of variation (CV; $\frac{\sigma}{\mu}$), the probability of detecting a change in survival probabilities, relative bias ($\frac{(\bar{e_{i}}-t)}{t}*100$), and root mean square error (RMSE; $\sqrt{\text{E}[(\bar{e_i}-t)^2]}$). The CV is a useful metric for understanding precision or the degree of dispersion around the mean and is used in MMPA permit applications for the sea lion branding program. Relative bias is a measure of whether estimates are systematically over- or under-estimated relative to the true data-generating value and RMSE is a combined measure of variance and bias. 

To examine the probability of detecting a difference between estimated survival probabilities and a "baseline" rate, we generated annual survival estimates using a logit normal distribution with a mean rate equal to the empirical mean multiplied by an age-specific percent difference and a standard deviation equal to that of the empirical eDPS estimates. We then examined the probability of whether the credible intervals for each survival rate excluded the original "baseline" rate at 5, 10, 15, and 20 years into the study. We examined the probability of detecting a "smaller" decrease in survival (15%, 10%, 5%, 2.5% of the baseline for pups, age-1:2, juveniles, and adults, respectively) versus a "larger" decrease in survival (20%, 15%, 10%, 5%). For example, suppose we estimated a long-term average pup survival rate of 0.55 and are interested in ascertaining the survey features with a high probability of detecting a true survival rate that is 20% lower (a larger decrease) than that baseline. In this case, $\phi^{\text{p}}_{\text{sim}} = {\text{lnorm}}(0.55-0.55*0.20, \sigma_\phi^{\text{p}})$ and we recorded whether the upper limit of the 95% credible interval was less than or equal to 0.55 for each simulated dataset. These percent decrease threshold values were loosely chosen based on the age-specific variability in empirical survival estimates for the eDPS. It is important to note that this approach does not aim to detect a *trend* in survival estimates nor does it convey information about *when* a change occurred, just that we can be 95% confident that the mean survival rate over the entire study period (10 or 20 years) excludes a previous "baseline" rate or benchmark of interest.   

For each scenario, 100 unique datasets were simulated and fit using NIMBLE (NIMBLE Development Team 2019) within the R programming environment (R Core Development 2020) using three Markov chain Monte Carlo (MCMC) chains with 20,000 iterations, 10,000 burn-in, and a thinning rate of 3, resulting in 10,000 MCMC samples. Convergence was evaluated using visual inspection of MCMC chains and the Brooks-Gelman-Rubin statistic (Gelman & Rubin 1992; Brooks & Roberts 1998) $\hat{R}$ < 1.1. The proportion of simulations where all parameters converged was high (~95%), though convergence was a bit lower for some scenarios. 

### Results  

Model performance is detailed for each metric below, but was generally consistent across all metrics of precision and bias. In general, model performance degrades most notably across branding frequency, branding cohort size, and study time horizon. In terms of deriving accurate and unbiased estimates of a mean survival probability, precision goals stated in MMPA permits can be reliably achieved for all age classes with either a 20-year study horizon or annual branding. The probability of detecting a change in survival varies considerably across simulation scenarios and highlights the power of increasing branding frequency and cohort sample sizes. In general, the estimation of pup and adult survival often show stronger patterns across the survey scenarios, but likely for two different reasons. Pup survival is intentionally simulated to have higher variability to reflect ecological theory and empirical estimates, and therefore may have poorer precision or increased bias. Adult 5$^+$ survival, on the other hand, has minimal simulated variability but will always be informed by fewer branded cohorts, which can be influential in the shorter study time horizon (e.g., adult survival would only be informed by 2 cohorts in a 10-year study with triennial branding). 

#### Coefficient of variation   
The CV values were relatively low, varied for each age class, and followed an expected pattern across survey features, with the most precise estimates arising in scenarios with larger cohort branding sizes, the longer study horizon, and more frequent branding (`r figs('cv_cont_dot', display = 'cite')`). Posterior median CVs were generally low, but smaller for juveniles and adults (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiJ', 'phiA'), 'value']),2)`) and higher for younger age classes (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiP', 'phi1', 'phi2'), 'value']),2)`) across all scenarios. For the 20-year study horizon and medium cohort size, CV values for pup survival decreased by `r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 3, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% when moving from triennial to biennial branding and decreased by 
`r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'High' & mean.cv.20$survey_freq == 2, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% 
when moving from low to high detection rates at biennial branding (i.e., branding frequency has a stronger effect than detection). Cohort sample size and branding frequency have a greater effect on CV values in scenarios with the 10-year study horizon than the 20-year study horizon where precision is generally higher.  

In examining the probability of the CV being below 0.125 (the threshold used in MMPA permit applications for sea lion branding), we can see the importance of a longer study time horizon and branding frequency. The MMPA permit application benchmark can be achieved reliably (>75%) for juveniles and adults in all scenarios and achieved reliably for younger age classes in scenarios with: (1) annual branding and medium-high detection, (2) biennial branding over a longer study with medium-high detection, or (3) triennial branding over a longer study with larger sample sizes, though the probability for pup survival in these instances is still lower (50-75%) (`r figs('cv_thresh_dot', display = 'cite')`). In short, branding cohort size and branding frequency can compensate for other "losses" of information to a degree that increasing detection probability (within the range studied here) cannot. Study length, in this case though, provides the greatest improvements: the probability of achieving a CV<0.125 for pup survival for a cohort size of N = 100 individuals increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 3 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% by moving from triennial to biennial branding in a 10-yr study whereas it increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 20, 'value_cat'], 2)*100`% when maintaining biennial branding but moving from a 10-yr to a 20-yr study. 

#### Detecting a difference in survival  
The patterns in the probability of detecting a difference between the mean survival probabilities estimated over the study period and a pre-established "baseline" are similar to those of the CV results. Here, however, it is important to focus on relative trends, as the reported probabilities are a direct product of the percent difference that is examined - an analytical choice that could easily be modified for other circumstances. As described above, we examined two sets of percent differences: a smaller (15%, 10%, 5%, 2.5% for pups, age-1:2, juveniles, and adults, respectively) and larger (20%, 15%, 10%, 5%) difference between baseline and true data-generating values. Naturally, the probability of detecting a small difference will be lower than that of detecting a large difference, as the inherent uncertainty in survival estimates captured by the posterior distribution would be more likely to overlap with a baseline threshold that is closer to the true data-generating value. We largely report results for scenarios examining data generated with a large difference from a baseline (see Appendix for probabilities of detecting a small difference). 

Overall, the probability of detecting a difference in survival varied by age class and across branding frequency, cohort size, and study length (`r figs('cri_dot_big', display = 'cite')`). In a 10-yr study, the probability of detecting a difference was consistently lowest for adults. The probability of reliably (>75%) detecting a large difference in adult survival in a 10-yr study was only achieved in the best survey circumstance (annual branding of the largest cohort size and highest detection level) and was generally only reliably achieved for other age classes with annual branding. In contrast, a large difference in adult survival was reliably detected over a 20-yr study horizon in all survey scenarios except triennial branding of the smallest cohort size. However, reliably detecting large differences in pup and yearling survival over the 20-yr study horizon still required either (a) annual branding or (b) biennial branding and larger cohort sizes, and was not reliably achieved in any scenario with triennial branding (`r figs('cri_dot_big', display = 'cite')`). The probabilities of detecting a smaller difference in survival were overall much lower and could only be reliably achieved for pups in a 10-yr study under the best survey circumstances or with a 20-yr study (Appendix). 

As noted above, we also examined the probability of detecting a difference in survival across a combined "survey effort" metric that combined branding frequency and detection probability (`r figs('effort_plot', display = 'cite')`a). These results highlight the strength of increasing branding frequency in improving estimation relative to increasing detection probability (`r figs('effort_plot', display = 'cite')`b). Specifically, in a 20-yr study with a smaller (N = 50) branding cohort size, increasing survey effort by improving branding frequency alone increased the probability of detecting a large difference in survival by `r abs(round(effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value']-effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'High', 'value']/effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value'],2))*100`% (`r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value']*100`% to `r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'High', 'value']*100`%) compared to the `r abs(round(effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value']-effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Detection only' & effort_dat$step == 'High', 'value']/effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value'],2))*100`% increase (`r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value']*100`% to `r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'Pup' & effort_dat$category == 'Detection only' & effort_dat$step == 'High', 'value']*100`%) achieved by increasing detection probabilities alone. This pattern was similar across cohort sample sizes, study lengths, and both small and large survival difference thresholds (`r figs('effort_plot', display = 'cite')`b). The probability of detecting differences in survival of all age classes is presented in the Appendix. 

#### Relative bias and RMSE
Relative bias did not exhibit strong patterns across age classes and was generally low (<`r round(max(mean.rel.bias.20$value),1)`%) for all survey scenarios (`r figs('bias_dot', display = 'cite')`). Relative bias for pup survival was on average `r round(mean(mean.rel.bias.20[mean.rel.bias.20$length == 10 & mean.rel.bias.20$variable == 'phiP', 'value']),1)`% for all scenarios with a 10-yr study horizon compared to `r round(mean(mean.rel.bias.20[mean.rel.bias.20$length == 20 & mean.rel.bias.20$variable == 'phiP', 'value']),1)`% for 20-yr study designs. Similarly, average relative bias for pup survival was higher for triennial branding scenarios (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Triennial' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) compared to that of biennial (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Biennial' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) and annual (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Annual' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) branding, though these differences are relatively small in this context.  

Model performance in terms of RMSE followed an expected pattern across survey features and values were generally very low (<`r round(max(mean.rmse.20$value),2)`) across all survey scenarios (`r figs('rmse_dot', display = 'cite')`). Specifically, RMSE values were lower (indicating greater precision and lower bias) for juvenile and adult survival and higher for younger age classes. Values were higher for triennial branding and lower branding cohort sizes for both 10- and 20-year study horizons.  
 
### Discussion  
 
This study examined the precision and bias in the estimation of vital rates across a range of mark-recapture survey features to inform the development of effective survey designs for Steller sea lions that meet management objectives for the two distinct population segments. Our results highlight numerous survey design configurations that reliably (>75% probability) produce CV values that meet target thresholds and reliably detect a difference in survival probabilities, though the longer study horizon was important in achieving these metrics for the survival probabilities of younger individuals that are by nature more variable. Overall, we found that increasing branding frequency and study length are more influential than increasing detection probabilities for a given branding cohort size. Taken together, our findings emphasize the importance of evaluating model performance across survey design features with specific management targets, conservation goals, and risk thresholds in mind.
In the context of this study, our results as applied to existing and future Steller sea lions confirm that a comprehensive range-wide monitoring program for the species must account for regional differences in the size and longevity of the existing marked population, constraints on future branding cohort size, rookery accessibility, and management goals given populations’ conservation status. For the eDPS and rookeries in the wDPS to the east of Samalga Pass, the survey design which has typically had cohort sizes of 150-200 individuals and biennial branding frequency over 15-20 years would be sufficient to continue reliably achieving target CV precision thresholds and being able to detect a trend in survival for all age classes examined here as long as medium to high detection rates were maintained. If resources were limited, monitoring for the eDPS could be relaxed to triennial marking, though the probability of detecting a change or trend in survival for pups would likely become less reliable (<75%). Achieving these thresholds is conditional on continuing to resight preexisting individuals already in the marked population (i.e., focusing on results from the 20-year study horizon), as the probabilities for detecting a change in survival and achieving target CV values were considerably lower for shorter study horizons.
In contrast to the eDPS and stable subregions of the wDPS, our results indicate that historical and ongoing mark-resight survey effort for rookeries in the wDPS to the west of Samalga Pass has been insufficient to reliably achieve CV precision targets for younger age classes or detect differences in survival probabilities for any age. This inadequacy is largely due to the combination of the shorter study period (branding began in 2011 rather than 2001) and the smaller branding cohort sizes. As future branding cohort sizes will be limited by dwindling rookery population size, increasing sample sizes through either annual branding (largely infeasible due to costs of accessing remote rookeries in the central and western Aleutians) or simply continuing to grow the marked population via biennial branding to extend the study horizon to more closely match that of the other regions. However, even in survey scenarios with 20-year study horizons, the probability of detecting a difference in survival with smaller cohort sizes (i.e., N = 50) was still only approximately 45-60% for pups and yearlings. Considering these constraints, it will be important to reassess conservation targets and carefully weigh the costs and benefits of potential monitoring strategies for these declining subregions. Though specific vital rate trends or precision targets are not directly considered in listing decisions for this species, the abundance trends in these subregions have been deciding factors in maintaining the Endangered status of the wDPS.
Though we have examined model performance across numerous survey features, future work could improve upon this study by optimizing survey design choices by including a robust analysis of monitoring costs. Incorporating cost information into conservation planning, particularly spatially-explicit cost information, can improve the efficiency of monitoring programs (Naidoo et al. 2006, Torrubia et al. 2014, Galvez et al. 2016) but can also exacerbate disagreements about conservation priorities (Armsworth et al. 2017). Efforts to incorporate and assess monitoring costs are often hampered by the challenges of reporting relevant information (White et al. 2022), including the difficulties in estimating expenditures for a specific survey feature (i.e., costs of spending additional days in the field to increase detection versus additional time marking and releasing additional individuals). Another avenue for future research would include conducting a simulation analysis examining the performance of potential survey designs using an integrated population model framework that included both mark-recapture and count survey data, both of which are available for this and many other well-monitored species. Estimating demographic rates for Steller sea lions using an integrated population model has been shown to reduce uncertainty in survival and reproduction (Warlick et al. in review), indicating that the probabilities of detecting a difference in survival or achieving CV precision targets would be higher for a given mark-recapture survey design if aerial survey data were also used. Also, an integrated population model framework would likely provide additional alternative survey designs, particularly where other constraints (i.e., cohort sample size or cost-prohibitive remote survey locations) would likely be ameliorated by an additional data stream.

Endangered species recovery programs in the United States have been underfunded in recent decades, with available funding is allocated disproportionately across species (Evans et al. 2016). The resulting funding shortages and monitoring inertia often lead to mismatches between recommended recovery actions and the type, quality, or spatial extent of monitoring data available to evaluate whether management objectives are being met. Additionally, natural resource managers must often choose to allocate limited funding resources between ongoing monitoring programs and other activities such as threat abatement or habitat restoration that might have more direct effects on population dynamics or abundance. In a review of almost 200 recovery plans, Campbell et al. (2002) found that proposed and implemented monitoring programs generally did not address the most notable threats for a given species, highlighting a tendency to prioritize monitoring (that may not be able to detect population-level responses to management actions or elucidate potential paths toward recovery) over other recovery actions. These situations may arise because, as Nichols & Williams (2006) point out, general “surveillance” monitoring may be triggered by an identified decline in abundance and the desire to understand the reason for the decline rather than finding actions to promote recovery. [For Steller sea lions….] These constraints may dampen the ability of this and other similar monitoring programs to expand or enhance monitoring efforts in response to changing management needs and/or a growing need to ramp up monitoring effects of climate-change related effects. 
 
Assessments of wildlife population dynamics, abundance trends, and progress toward recovery rely on the ability to gather monitoring data with sufficient precision to answer pressing conservation questions. All too often, optimizing survey designs prior to implementing monitoring activities is limited by funding, time, lack of expertise, or inadequately defined monitoring objectives. The simulation analysis presented here was motivated by the need to design effective and efficient mark-resight surveys for Steller sea lions and highlights the degree to which increasing certain metrics of survey effort can improve demographic estimation. This framework is applicable to other populations or species and can inform monitoring survey designs that promote an effective allocation of scarce and dwindling funding in the future as the need for conservation and monitoring of depleted, theatened species will likely grow due to climate change. 

### Figures   

```{r cv continuous dot, fig.height = 6, fig.width = 7}

cv_cont_dot

```
`r figs('cv_cont_dot', caption = 'Mean and 95% quantiles for coefficient of variation (CV) values for age-specific survival probabilities across survey design features, including branding frequency, branding cohort size, study time horizon, and mark-resight detection probability across all simulations (n = 100).')`


```{r cv threshold dot, fig.height = 6, fig.width = 8}

cv_thresh_dot

```
`r figs('cv_thresh_dot', caption = 'Probability of the coefficient of variation for age-specific survival probabilities being less than 0.125 across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`


```{r detect change, fig.height = 6, fig.width = 8}

cri_dot_big

```
`r figs('cri_dot_big', caption = 'Probability of detecting a larger difference in age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`

```{r effort grid, fig.height = 4, fig.width = 6, eval = F}

# effort_grid

```
<!-- `r figs('effort_grid', caption = 'Schematic of the combinations of branding frequency and detection features that comprise the combined survey effort levels of low, medium, and high.')` -->

```{r effort, fig.height = 6, fig.width = 8, eval = F}
# 
# effort_dot
# 
```
<!-- # `r figs('effort_dot', caption = 'Probability of detecting smaller and larger differences in pup survival with successive gains in survey effort (combinations of detection probability and branding frequency) across branding cohort size and study time horizon.')` -->

```{r effort combined, fig.height = 6, fig.width = 9}

effort_plot

```
`r figs('effort_plot', caption = '(a) Schematic of the combinations of branding frequency and detection features that comprise the combined survey effort levels of low, medium, and high, and (b) Probability of detecting smaller and larger differences in pup survival with successive gains in survey effort (combinations of detection probability and branding frequency) across branding cohort size and study time horizon.')`

```{r bias fig, fig.height = 5, fig.width = 7}

bias_dot

```
`r figs('bias_dot', caption = 'Mean relative bias (%) for age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`


```{r RMSE fig, fig.height = 5, fig.width = 7}

rmse_dot

```
`r figs('rmse_dot', caption = 'Mean root mean square error (RMSE) for age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`

### Literature cited

Armsworth, P.R., Jackson, H.B., Cho, S.-H., Clark, M., Fargione, J.E., Iacona, G.D., Kim, T., Larson, E.R., Minney, T., Sutton, N.A., 2017. Factoring economic costs into conservation planning may not improve agreement over priorities for protection. Nat Commun 8, 2253. https://doi.org/10.1038/s41467-017-02399-y

Burton, A.C., Neilson, E., Moreira, D., Ladle, A., Steenweg, R., Fisher, J.T., Bayne, E., Boutin, S., 2015. REVIEW: Wildlife camera trapping: a review and recommendations for linking surveys to ecological processes. Journal of Applied Ecology 52, 675–685. https://doi.org/10.1111/1365-2664.12432

Campbell, S.P., Clark, J.A., Crampton, L.H., Guerry, A.D., Hatch, L.T., Hosseini, P.R., Lawler, J.J., O’Connor, R.J., 2002. AN ASSESSMENT OF MONITORING EFFORTS IN ENDANGERED SPECIES RECOVERY PLANS. Ecological Applications 12, 674–681. https://doi.org/10.1890/1051-0761(2002)012[0674:AAOMEI]2.0.CO;2

Cormack, R. M. 1964. Estimates of survival from the sighting of marked animals. Biometrika 51:429–438.

Del Vecchio, S., Fantinato, E., Silan, G., Buffa, G., 2019. Trade-offs between sampling effort and data quality in habitat monitoring. Biodivers Conserv 28, 55–73. https://doi.org/10.1007/s10531-018-1636-5

Evans, D.M., Che-Castaldo, J.P., Crouse, D., Davis, F.W., Epanchin-Niell, R., Flather, C.H., Frohlich, R.K., Goble, D.D., Li, Y.-W., Male, T.D., Master, L.L., Moskwik, M.P., Neel, M.C., Noon, B.R., Parmesan, C., Schwartz, M.W., Scott, J.M., Williams, B.K., 2016. Species recovery in the United States: Increasing the effectiveness of the Endangered Species Act.

Field, S.A., Tyre, A.J., Possingham, H.P., 2005. Optimizing allocation of monitoring effort under economic and observation constraints.. Journal of Wildlife Management 69, 473–482. https://doi.org/10.2193/0022-541X(2005)069[0473:OAOMEU]2.0.CO;2

Gálvez, N., Guillera-Arroita, G., Morgan, B.J.T., Davies, Z.G., 2016. Cost-efficient effort allocation for camera-trap occupancy surveys of mammals. Biological Conservation 204, 350–359. https://doi.org/10.1016/j.biocon.2016.10.019

Gonzalez, L.F., Montes, G.A., Puig, E., Johnson, S., Mengersen, K., Gaston, K.J., 2016. Unmanned Aerial Vehicles (UAVs) and Artificial Intelligence Revolutionizing Wildlife Monitoring and Conservation. Sensors 16, 97. https://doi.org/10.3390/s16010097

Ivan, J.S., White, G.C., Shenk, T.M., 2013. Using simulation to compare methods for estimating density from capture–recapture data. Ecology 94, 817–826. https://doi.org/10.1890/12-0102.1

Johnston, A., Fink, D., Reynolds, M.D., Hochachka, W.M., Sullivan, B.L., Bruns, N.E., Hallstein, E., Merrifield, M.S., Matsumoto, S., Kelling, S., 2015. Abundance models improve spatial and temporal prioritization of conservation resources. Ecological Applications 25, 1749–1756. https://doi.org/10.1890/14-1826.1

Jolly, G. M. 1965. Explicit estimates from capture-recapture data with both death and immigration-stochastic model. Biometrika 52:225–248.

Kristensen, T.V., Kovach, A.I., 2018. Spatially explicit abundance estimation of a rare habitat specialist: implications for SECR study design. Ecosphere 9, e02217. https://doi.org/10.1002/ecs2.2217

Lanier, W.E., Bailey, L.L., Muths, E., 2016. Integrating biology, field logistics, and simulations to optimize parameter estimation for imperiled species. Ecological Modelling 335, 16–23. https://doi.org/10.1016/j.ecolmodel.2016.05.006

Little, L.R., Punt, A.E., Dichmont, C.M., Dowling, N., Smith, D.C., Fulton, E.A., Sporcic, M., Gorton, R.J., 2016. Decision trade-offs for cost-constrained fisheries management. ICES Journal of Marine Science 73, 494–502. https://doi.org/10.1093/icesjms/fsv206

Lyons, J.E., Kendall, W.L., Royle, J.A., Converse, S.J., Andres, B.A., Buchanan, J.B., 2016. Population size and stopover duration estimation using mark–resight data and Bayesian analysis of a superpopulation model. Biometrics 72, 262–271. https://doi.org/10.1111/biom.12393

Naidoo, R., Balmford, A., Ferraro, P., Polasky, S., Ricketts, T., Rouget, M., 2006. Integrating economic costs into conservation planning. Trends in Ecology & Evolution 21, 681–687. https://doi.org/10.1016/j.tree.2006.10.003

Nichols, J.D., Williams, B.K., 2006. Monitoring for conservation. Trends in Ecology & Evolution 21, 668–673. https://doi.org/10.1016/j.tree.2006.08.007

Peel, D., Bravington, M., Kelly, N., Double, M.C., 2015. Designing an effective mark–recapture study of Antarctic blue whales. Ecological Applications 25, 1003–1015. https://doi.org/10.1890/14-1169.1

Reynolds, J.H., Thompson, W.L., Russell, B., 2011. Planning for success: Identifying effective and efficient survey designs for monitoring. Biological Conservation, Ecoregional-scale monitoring within conservation areas, in a rapidly changing climate 144, 1278–1284. https://doi.org/10.1016/j.biocon.2010.12.002

Seber, G. A. 1965. A note on the multiple-recapture census. Biometrika 52:249–259.

Sims, M., Wanless, S., Harris, M.P., Mitchell, P.I., Elston, D.A., 2006. Evaluating the power of monitoring plot designs for detecting long-term trends in the numbers of common guillemots. Journal of Applied Ecology 43, 537–546. https://doi.org/10.1111/j.1365-2664.2006.01163.x

Sollmann, R., Gardner, B., Belant, J.L., 2012. How Does Spatial Study Design Influence Density Estimates from Spatial Capture-Recapture Models? PLOS ONE 7, e34575. https://doi.org/10.1371/journal.pone.0034575

Sun, C.C., Fuller, A.K., Royle, J.A., 2014. Trap Configuration and Spacing Influences Parameter Estimates in Spatial Capture-Recapture Models. PLOS ONE 9, e88025. https://doi.org/10.1371/journal.pone.0088025

Torrubia, S., McRae, B.H., Lawler, J.J., Hall, S.A., Halabisky, M., Langdon, J., Case, M., 2014. Getting the most connectivity per conservation dollar. Frontiers in Ecology and the Environment 12, 491–497. https://doi.org/10.1890/130136

White, T.B., Petrovan, S.O., Booth, H., Correa, R.J., Gatt, Y., Martin, P.A., Newell, H., Worthington, T.A., Sutherland, W.J., 2022. Determining the economic costs and benefits of conservation actions: A decision support framework. Conservation Science and Practice 4, e12840. https://doi.org/10.1111/csp2.12840

Wilton, C.M., Puckett, E.E., Beringer, J., Gardner, B., Eggert, L.S., Belant, J.L., 2014. Trap Array Configuration Influences Estimates and Precision of Black Bear Density and Abundance. PLOS ONE 9, e111257. https://doi.org/10.1371/journal.pone.0111257

Yackulic, C.B., Korman, J., Yard, M.D., Dzul, M., 2018. Inferring species interactions through joint mark–recapture analysis. Ecology 99, 812–821. https://doi.org/10.1002/ecy.2166


### Appendix  

In this study, we examined model performance in terms of the precision of survival probabilities and the probability of detecting a difference in survival between the true data-generating value and a percent decrease threshold value. In the main text, we reduced the number of features or age-specific survival probabilities for clarity. In this appendix, we present coefficient of variation (CV) values and the probability of detecting a difference in survival across additional branding cohort sizes (N = 50, 75, 100, 150, and 200) and for all of the age-specific survival probabilities. 

As reported in the main text, CV values are lower with increased sample size and branding frequency, with the pattern being particularly evident for younger age groups (`r figs('cv_heat_cont', display = 'cite')`). These patterns are also reflected in the probability of the CV being below 0.125, which can be reliably achieved for younger age group survival probabilities only either with annual branding, biennial branding and a longer study period, or triennial branding and a longer study period and larger cohort branding size (`r figs('cv_thresh_heat', display = 'cite')`). When examining model performance across the combined "survey effort" metric (combinations of detection probability and branding frequency, see main text and Figure 4b), the probability of a lower CV is reliably achieved for juveniles and adults in almost all survey scenarios (`r figs('effort_cv_dot', display = 'cite')`). For younger ages, however, this threshold is reliably achieved with a shorter study period only with higher survey effort generated by increasing branding frequency and is not achieved when detection probability is increased alone (`r figs('effort_cv_dot', display = 'cite')`). For a longer study period, lower CV values can be reliably achieved at medium levels of survey effort and larger branding cohort sizes (`r figs('effort_cv_dot', display = 'cite')`). 

In terms of examining the probability of detecting a difference in survival, values are low for the 5-yr study horizon and increase as the study period lengthens, as expected (`r figs('cri_dot_app', display = 'cite')`). Across the "survey effort" metric, reliably detecting a small difference in survival for juveniles and adults was only achieved in scenarios with a longer study period, larger cohort sizes, and the highest level of survey effort. For younger age groups, the probability of detecting a small difference in survival exceeded 75% in scenarios with the shorter study time period and larger cohort sizes and survey effort (`r figs('effort_dot_app', display = 'cite')`). The probabilities of detecting a larger difference in survival followed similar patterns but were higher (`r figs('effort_dot_app', display = 'cite')`). 


```{r CV heatmap all facets, fig.height = 6, fig.width = 8}

cv_heat_cont

```
`r figs('cv_heat_cont', caption = 'Mean coefficient of variation (CV) for age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`

```{r CV threshold heatmap all facets, fig.height = 6, fig.width = 8}

cv_thresh_heat

```
`r figs('cv_thresh_heat', caption = 'The probability of coefficient of variation (CV) being below 0.125 for age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`

```{r CV effort all ages}

effort_cv_dot

```
`r figs('effort_cv_dot', caption = 'The probability of coefficient of variation (CV) being below 0.125 for age-specific survival probabilities across survey design features, including study time horizon, cohort size, and survey effort (combinations of detection probability and branding frequency) across all simulations (n = 100).')`


```{r change all ages, fig.height = 7, fig.width = 9}

cri_dot_app

```
`r figs('cri_dot_app', caption = 'The probability of detecting a smaller or larger difference in age-specific survival probabilities across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across all simulations (n = 100).')`

```{r cri effort all ages}

effort_dot_app

```
`r figs('effort_dot_app', caption = 'The probability of detecting a small or large difference in age-specific survival probabilities across survey design features, including study time horizon, cohort size, and survey effort (combinations of detection probability and branding frequency) across all simulations (n = 100).')`


