---
title: "SSL Future Proof Project Update - Jan 2023"
output: html_document
---

```{r setup, include=FALSE, fig.align = 'center'}

knitr::opts_chunk$set(echo = FALSE, eval = T, message = F, warning = F, fig.align = 'center')

library(here) #v1.0.1
library(dplyr) #v1.0.5
library(nimble) #v0.12.1
library(coda)
library(ggh4x)
library(readr)
library(knitr)
library(Hmisc)
library(stringr)
library(captioner)

#functions to use for calling figures/tables
figs <- captioner(prefix = "Figure")
tbls <- captioner(prefix = "Table")

source(here::here('scripts', 'PlotTheme.R'))

```

```{r scenarios and convergence}

sc <- c(1:45)

scenarios <- data.frame(scenario = c(sc),
                        survey_freq = c(rep(1,15), rep(2,15), rep(3,15)),
                        detection = c(rep(c('Low', 'Low', 'Low', 'Low', 'Low',
                                            'Med', 'Med', 'Med', 'Med', 'Med', 
                                            'High', 'High', 'High', 'High', 'High'), 3)),
                        N = c(rep(c(50,75,100,150,200), 9)))


#for figure legends
phi_pars <- c('phi[P]','phi[1]', 'phi[2]', 'phi[J]', 'phi[A]')
p_pars <- c('p[1]', 'p[2]', 'p[J]', 'p[A]') 
freq_labels <- c('1' = 'Annual', '2' = 'Biennial', '3' = 'Triennial')
occ_labels <- c('10' = '10 yrs', '20' = '20 yrs')

```


```{r cv}

#load in results for 10-yr study horizon
cv.files7 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv7', all.files = FALSE, full.names = F)

cv.files8 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv8', all.files = FALSE, full.names = F)

cv.files9 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv9', all.files = FALSE, full.names = F)

cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files12 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv12', all.files = FALSE, full.names = F)

cv.files <- c(cv.files7, cv.files8, cv.files9, cv.files10, cv.files11, cv.files12)


cv <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv <- rbind(cv, temp)

} #rds file

cv <- cv %>%
  filter(rhat < 1.1) 

mean.cv <- data.frame(cv) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

mean.cv.thresh <- data.frame(cv) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

#load in results from 20-yr study and merge
cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files14 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv14', all.files = FALSE, full.names = F)

cv.files15 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv15', all.files = FALSE, full.names = F)

cv.files18 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv18', all.files = FALSE, full.names = F)

cv.files19 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv19', all.files = FALSE, full.names = F)

cv.files22 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'),
                         pattern = 'cv22', all.files = FALSE, full.names = F)

cv.files23 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv23', all.files = FALSE, full.names = F)

cv.files26 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv26', all.files = FALSE, full.names = F)

cv.files27 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv27', all.files = FALSE, full.names = F)

cv.files30 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv30', all.files = FALSE, full.names = F)

cv.files31 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv31', all.files = FALSE, full.names = F)


cv.files <- c(cv.files10, cv.files11, cv.files14, cv.files15, cv.files18, cv.files19,
              cv.files22, cv.files23, cv.files26, cv.files27, cv.files30, cv.files31)

cv.20 <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv.20 <- rbind(cv.20, temp)

} #rds file

cv.20 <- cv.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) #%>%
  # bind_rows(cv)

mean.cv.20 <- data.frame(cv.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 20) %>%
  bind_rows(mean.cv)

### figures

## continuous dotplots
dotplot_dat_mean <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_up <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(upper = quantile(value, probs = 0.975)) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_low <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(lower = quantile(value, probs = 0.025)) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat <- dotplot_dat_mean %>%
  merge(dotplot_dat_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_dat_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection')

#study horizon
cv_cont_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_errorbar(aes(ymin = lower, ymax = upper, x = survey_freq), width = 0.1) +
  xlab('Branding frequency') + ylab('CV') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')


##threshold approach

#dotplot 
dotplot_dat <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  transform(value_cat = value<0.125) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection')

#no quantile error bars on yes/no 
cv_thresh_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value_cat, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  xlab('Branding frequency') + ylab('Probability of cv < 0.125') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

###appendix figures -- none unless want all sample sizes shown

##continuous cv
plot_dat <- mean.cv.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_heat_cont <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "cv",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##threshold

#heatmaps
mean.cv.thresh.20 <- data.frame(cv %>% transform(length = 10)) %>% 
  bind_rows(cv.20 %>% transform(length = 20)) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), 
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size')

plot_dat <- mean.cv.thresh.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_thresh_heat <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') + ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of \n cv < 0.125",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


```


```{r detecting change}

#load in results from 10-yr
cri.scenarios <- c('dec_little', 'dec_big')
append <- c(5,10)

cri.all <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -5,-5)) %>%
  transform(length = append[a]) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all <- rbind(cri, cri.all)

} #rds file
} #j


mean.cri <- data.frame(cri.all) %>%
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') 

#load in results from 20-yr
cri.all.20 <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop', 
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -6,-5)) %>%
  transform(length = append[a]+10) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all.20 <- rbind(cri, cri.all.20)

} #rds file
} #j

mean.cri.20 <- data.frame(cri.all.20) %>%
  #are these just all the unfinished/unfilled sim dataframe rows? 
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  bind_rows(mean.cri)

#plots

#dotplot

dotplot_dat <- cri.all.20 %>% transform(length = 20) %>% 
  bind_rows(cri.all %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N, threshold) %>%
    dplyr::summarize(value = mean(value, na.rm = T), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

cri_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) & length %in% c(10,20)
                               &  threshold == 'dec_big'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  xlab('Branding frequency') + ylab('Probability of detecting difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

#appendix figures

#all facets
plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & change size', 
            samp_size = 'Sample size & study length')

#all facets continuous
cri_all_cont_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#all facets categorical
cri_all_cat_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting difference in survival",
                    # values = c('firebrick3', 'orange', 'steelblue2'))
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))

#fewer facets
 plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable) & length %in% c(10,20)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size')
 
#big decrease in survival 
cri_big_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')), 
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of detecting difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) 

#categorical, small decrease
cri_big_cat_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')),
       aes(x = factor(detection), y = variable, fill = value_cat), alpha = 0.3) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting small change",
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))



```

```{r collapsed detecting change}

#mean.cri.20 contains the mean probability (across simulations) where the cv < 0.125.

#values for the scenario with the "least" amount of contributing information
#i.e., triennial sampling, N = 50, 10 years, low detection (scenario 31)

cri_least_info <- mean.cri.20 %>% transform(samp_size = 'Sample size') %>%
  dplyr::select(!survey_frequency) %>%
  filter(detection == 'Low' & length %in% c(10,20) &
           survey_freq == 3 & N %in% c(50, 100, 200)) %>%
  dplyr::select(c(variable, N, value, length, threshold)) %>%
  dplyr::rename(min_val = value)

cri_delta <- mean.cri.20 %>% filter(length %in% c(10,20)) %>%
    filter(N %in% c(50, 100, 200)) %>% 
  merge(cri_least_info, by = c('variable', 'N', 'length', 'threshold')) %>%
  transform(delta = value-min_val) %>%
  transform(det_cat = as.numeric(factor(detection)),
            N_cat = as.numeric(factor(N))) %>%
  # filter(variable == 'phiP') %>%
  filter(variable %in% c('phiP', 'phi1')) %>%
  transform(survey_cat = 4-as.numeric(factor(survey_freq))) %>%
  transform(step = N_cat + survey_cat + det_cat) %>%
  transform(step = ifelse(detection == 'Low' & survey_freq == 3, 0, step))

cri_delta_steps <- cri_delta %>% 
  # filter(N == 50 & variable == 'phiP') %>%
    filter(variable %in% c('phiP', 'phi1')) %>%
  transform(category = ifelse(step == 0, 'Baseline', 
                  ifelse(det_cat > 1 & survey_cat == 1, 'Detection only',
                  ifelse(survey_cat > 1 & det_cat == 1, 'Frequency only', 'Detection & frequency')))) %>%
  transform(step = ifelse(step == 0, 0,
                          ifelse(det_cat == 1 & survey_cat == 1, NA,
                            ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 1 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 1, 2, 
                            ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 2 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 2, 2, 
                            ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 3 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 3, 2, 
                            ifelse(det_cat == 1 & survey_cat == 1, NA, NA)))))))))) 

scenario_fill_cri <- expand.grid(step = 0,
              length = c(10,20),
              threshold = c('dec_little', 'dec_big'),
              N = c(50, 100, 200),
              category = c('Detection only', 'Frequency only', 
                                         'Detection & frequency')) %>%
  merge(cri_delta_steps %>% dplyr::select(length, threshold, min_val, category, variable, N), 
        by = c('category', 'N', 'length', 'threshold')) %>% 
  distinct() %>%
  dplyr::rename(value = min_val)
                            
plot_dat <- cri_delta_steps %>%
  dplyr::select(category, N, length, threshold, step, value, variable) %>%
  bind_rows(scenario_fill_cri) %>%
  filter(category != 'Baseline') %>%
  transform(threshold_name = factor(threshold, levels = c('dec_little', 'dec_big'), 
                                    labels = c('Small difference', 'Large difference'))) %>%
  transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Branding frequency only', 'Detection & branding frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High')))

#probability of detecting change.... 
effort_dot <- ggplot(plot_dat %>% filter(!is.na(step)) %>% filter(variable == 'phiP') %>%
         transform(samp_size = 'Sample size & study length') %>%
         transform(length = factor(length, labels = c('10 yrs', '20 yrs'))), 
       aes(factor(step), value, group = category, col = category)) +
  # geom_point(position = position_dodge(width = 0.1)) +
  geom_point() +
  geom_line() +
  facet_nested(threshold_name~samp_size+length+N) +
  xlab('Survey effort (detection + branding frequency)') + 
  ylab('Probability of detecting difference in pup survival') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_color_manual(values = rainbow2[-c(1,4,6)], name = '')

```


```{r relative bias}

bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias <- rbind(rel.bias, temp)

} #rds file

rel.bias <- rel.bias %>%
  filter(rhat < 1.1) %>%
  transform(length = 10)

mean.rel.bias <- data.frame(rel.bias) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)


bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias.20 <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias.20 <- rbind(rel.bias.20, temp)

} #rds file

rel.bias.20 <- rel.bias.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20)

mean.rel.bias.20 <- data.frame(rel.bias.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rel.bias) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and sample size') 

#figures
#heatmaps
plot_dat <- mean.rel.bias.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) 


bias_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
       aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Branding frequency') + ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(length = occ_labels),
             scales = 'free_x') +
  scale_fill_gradient2(name = "Relative bias (%)",
                      mid = "#FFFFFF", low = "deepskyblue1", high = "red2", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#dotplots
dotplot_mean <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value)*100, .groups = 'keep') 

dotplot_low <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(lower = quantile(value*100, probs = 0.025), .groups = 'keep')

dotplot_up <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(upper = quantile(value*100, probs = 0.975), .groups = 'keep')

dotplot_dat <- dotplot_mean %>% 
  merge(dotplot_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and sample size') %>%
  #filter out detection params
  filter(!is.na(variable))

bias_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  # geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 0), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Relative bias') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +

  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')


```

```{r RMSE}

rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse <- rbind(rmse, temp)

} #rds file

rmse <- rmse %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 10)

mean.rmse <- data.frame(rmse) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', 
            samp_size = 'Sample size') %>%
  transform(length = 10) 


rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse.20 <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse.20 <- rbind(rmse.20, temp)

} #rds file

rmse.20 <- rmse.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) 

mean.rmse.20 <- data.frame(rmse.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rmse) %>%
  transform(survey_frequency = 'Branding frequency & study length', 
            samp_size = 'Study horizon and sample size', det = 'Detection') %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial')))


#plots
plot_dat <- mean.rmse.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

rmse_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
                    aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Branding frequency') +
  ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "RMSE",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 8, vjust = 0.5),
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##dot plots
dotplot_dat <- rmse.20 %>% transform(length = 20) %>% 
  bind_rows(rmse %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  # dplyr::summarize(value = mean(value),
  #                  lower = quantile(value, probs = 0.025),
  #                  upper = quantile(value, probs = 0.975),
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

rmse_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  xlab('Branding frequency') + ylab('RMSE') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +

  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

```


### Introduction    

Important concepts/paragraphs

- Accurate/unbiased estimates are important for wildlife conservation and management
-- Status assessments (abundance), effects of changing environmental conditions (demography)
-- Have to achieve a certain degree of precision to be effective in meeting conservation and management goals (Reynolds et al)
-- These estimates can be expensive, invasive, disruptive, logistically challenging
-- Important to "optimize" trade-offs for managers, wildlife, and costs 

- Optimizing can be logistically challenging 
-- Costs can be difficult to quantify
-- Budgets can be difficult to predict/changing
-- Can change as project needs are distilled or population status changes over long-term
-- Some levers can be pulled, some can't
-- Metrics/goals might not be well defined
-- Usually not done before a sampling design, but just to ensure no concerning bias at given study features (Yackulic et al. 2018)
--- Examples

- Optimizing can be subjective  
-- Political/controversial/different stakeholders
-- Risk tolerance is usually difficult to elicit or poorly defined  
--- Examples lead into SSL

- Even if it is hard, it is worth doing
-- Benefits for SSL
-- Applicability for other populations
-- Conclusion sentence

### Methods  

#### Study system
This study aimed to inform mark-resight survey design for Steller sea lions throughout their range, where population size, population trend and status, rookery terrain, and rookery accessibility vary considerably. For the eDPS on the U.S. West Coast and up into southeast Alaska, population trends are stable or increasing, and constraints include X, Y, Z. For the wDPS whose range spans the Aleutian Islands in Alaska, population trends are increasing or stable to the east of Samalga Pass and declining to the west of Samalga Pass. Survey considerations and constraints for rookeries in the wDPS include X, Y, Z.
(Not much needed here because we're not deriving empirical estimates that need contextualizing -- or move to introduction?)
 
#### Data simulation and model description    
Mark-resight data were simulated over 10- and 20-year study horizons based on basic sea lion life history characteristics. Age class-specific survival and detection probabilities used as data-generating "true" values were based on empirical estimates from individuals branded, released, and resighted in the eastern DPS from 2001-2019. Temporal variance in survival probabilities was simulated based on the mean and standard deviation of age class-specific empirical estimates. Detection probabilities were assumed constant for each age class over the study period. Simulated data were fit to a Cormack Jolly Seber (Cormack 1964,) mark-resight model framework to estimate survival of five age classes (pups, age-1, age-2, juveniles (ages 3-4), and adults 5+) with true ecological states defined by an individual's age. The state process model,

\begin{equation}
z_{i,t} | z_{i,t-1} \sim ~ \text{categorical}(\Omega_{z_{i,t-1},i,t-1}) 
\end{equation}

describes the state *z* of individual *i* at occasion *t*, conditional on the individualâ€™s state at the previous occasion, modeled as categorically distributed according to transition array $\Omega$, which is composed of age group-specific survival probabilities ($\phi_\text{i,t}$). Fecundity was not of interest in this analysis and was therefore not incorporated into study design. Temporal variance in survival probabilities was modeled using penalized complexity priors (Simpson et al. 2017, van Erp et al. 2019), where for demographic rate parameter $\gamma$, 

\begin{equation}
\text{logit}(\gamma_\text{a,t}) = \mu_\text{a}^{\gamma} + \epsilon_\text{a,t}^{\gamma} 
\epsilon_\text{a,t}^{\gamma} \sim \text{normal}(0, \sigma_\epsilon)
\sigma_\epsilon \sim \text{exponential}(1) 
\end{equation}

where $\mu_\text{a}^{\gamma}$ is an age (*a*)-specific intercept estimated with back-transformed uninformative priors U(0,1) on the logit scale. $\epsilon_\text{a,t}^{\gamma}$ is an annual (*t*) random effect estimated with a normal distribution with mean zero and standard deviation estimated with a fixed shrinkage rate of exponential(1). This approach reduces the coefficient $\epsilon_\text{a,t}$ toward zero in the absence of strong support for an effect and can improve parameter estimability (Simpson et al. 2017).  

The observation process model included age class-specific observations of individuals based on detection probabilities that were assumed to be constant over the study period:

\begin{equation}
y_{i,t} | z_{i,t} \sim ~ \text{categorical}(\Theta_{z_{i,t} i,t})  (\#eq:obsproc)
\end{equation}

where observations $y_\text{i,t}$ conditional on the true state $z_\text{i,t}$ are categorically distributed with probability array $\Theta$, which is composed of an individual's detection probability at time *t*, $p_\text{i,t}$. The typical set of mark-recapture model assumptions applied, where it was assumed that branding did not affect detection probability, that survival of individuals was independent, there were no identification errors, mortality during the sampling season was negligible, and that there was no unmodeled heterogeneity in survival and detection probabilities.
 
#### Simulation scenarios  
The above model was fit across 90 scenarios composed of all combinations of branding cohort sizes (N = 50, 75, 100, 150, 200), branding frequency (annual, biennial, triennial), study horizon (10 years versus 20 years), and detection rates (low, medium, high). Detection rates varied by age group, with low and high levels set at +/- 20% of the age-specific empirical estimates (e.g., detection rate levels were 0.48, 0.6, 0.72 for pups and X, Y, Z for yearlings). Resighting effort was assumed to occur annually regardless of branding schedule due to the increasing feasibility and use of remote cameras for this and other wildlife populations (Burton et al. 2015). As we were not able to quantify the monetary costs of survey effort per individual sea lion branded or resighted to develop a robust cost-benefit optimization scheme across all survey features, we also examined model performance across a collapsed survey "effort" metric (specific combinations of branding frequency and detection probability levels) to highlight which might yield the best model performance. The levels of this survey effort metric were "low" (triennial branding with low detection probabilities), "medium" (biennial branding with medium detection), and "high" (annual branding and high detection). Annual branding may be unrealistic at most rookeries for Steller sea lions (disturbance and MMPA permit limitations, cost and logistics of surveying remote rookeries, etc.), but is included here as a point of comparison to the other branding frequency schedules and because it may likely be of interest to other wildlife populations or circumstances. Additionally, certain comparisons in the results section are highlighted based on the fact that branding cohort size may not be a survey feature that practitioners can easily modify (rookery size, number of consecutive visits to rookery, etc.). 
 
#### Model performance and fitting     
We assessed model performance across four metrics: coefficient of variation (CV; $\frac{\sigma}{\mu}$), the probability of detecting a change in survival rates, relative bias ($\frac{(\bar{e_{i}}-t)}{t}*100$), and root mean square error (RMSE; $\sqrt{\text{E}[(\bar{e_i}-t)^2]}$). The CV is a useful metric for understanding precision or the degree of dispersion around the mean that is used in MMPA permit applications for the sea lion branding program. Relative bias is a measure of whether estimates are systematically over- or under-estimated relative to the true data-generating value and RMSE is a combined measure of variance and bias. 

To examine the probability of detecting a difference between estimated survival rates and a "baseline" rate, we generated annual survival estimates using a logit normal distribution with a mean rate equal to the empirical mean multiplied by an age-specific percent difference and a standard deviation equal to that of the empirical eDPS estimates. We then examined the probability of whether the credible intervals for each survival rate excluded the original "baseline" rate (at 5, 10, 15, and 20 years into the study). We examined the probability of detecting a "smaller" decrease in survival (15%, 10%, 5%, 2.5% for pups, age-1:2, juveniles, and adults, respectively) versus a "larger" decrease in survival (20%, 15%, 10%, 5%). For example, suppose we estimate a long-term average pup survival rate of 0.55 and are interested in ascertaining the survey features with a high probability of detecting a true survival rate that is 20% (larger decrease) lower than that baseline. In this case, $\phi^{\text{p}}_{\text{sim}} = {\text{lnorm}}(0.55-0.55*0.20, \sigma_\phi^{\text{p}})$ and we recorded whether the upper limit of the 95% credible interval was less than or equal to 0.55 for each simulated dataset. These values were chosen losely based on the apparent age-specific variability in empirical survival estimates for the eDPS. It is important to note that this approach does not aim to detect a *trend* in survival estimates nor does it convey information about *when* a change occurred, just that we can be 95% confident that the mean survival rate over the entire study period (10 or 20 years) excludes a previous "baseline" rate or benchmark of interest.   

For each scenario, 100 unique datasets were simulated and fit using NIMBLE (NIMBLE Development Team 2019) within the R programming environment (R Core Development 2020) using three Markov chain Monte Carlo (MCMC) chains with 20,000 iterations, 10,000 burn-in, and a thinning rate of 3, resulting in 10,000 MCMC samples. Convergence was evaluated using visual inspection of MCMC chains and the Brooks-Gelman-Rubin statistic (Gelman & Rubin 1992; Brooks & Roberts 1998) $\hat{R}$ < 1.1. The proportion of simulations where all parameters converged was high (~95%), though convergence was a bit lower for some scenarios. 

### Results  

Model performance is detailed for each metric below, but was generally consistent across all metrics of precision and bias. In general, model performance degrades most notably across branding frequency, cohort sampling size, and study time horizon. In terms of deriving accurate and unbiased estiamtes of a mean survival probability, precision goals stated in MMPA permits can be reliably achieved for all age classes with either a 20-year study horizon or annual branding. The probability of detecting a change in survival varies considerably across simulation scenarios and highlights the power of increasing branding frequency and cohort sample sizes if detecting a change in survival is a high research priority (as opposed to just having precise mean survival estimates). In general, the estimation of pup and adult survival often show stronger patterns across the survey scenarios, but likely for two different reasons. Pup survival is intentionally simulated to have higher variability to reflect ecological theory and empirical estimates, and therefore may have poorer precision or increased bias. Adult 5+ survival, on the other hand, has minimal simulated variability but will always be informed by fewer branded cohorts, which can be influential in the shorter study time horizon (e.g., adult survival would only be informed by 2 cohorts in a 10-year study with triennial branding). 

#### Coefficient of variation   
The CV values were relatively low, varied for each age class, and followed an expected pattern across survey features, with the most precise estimates arising in scenarios with larger sample sizes, the longer study horizon, and more frequent branding (`r figs('cv_cont_dot', display = 'cite')`). Posterior median CVs were generally low, but smaller for juveniles and adults (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiJ', 'phiA'), 'value']),2)`) and higher for younger age classes (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiP', 'phi1', 'phi2'), 'value']),2)`) across all scenarios. For the 20-year study horizon and medium cohort size, CV values for pup survival decreased by `r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 3, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% when moving from triennial to biennial branding and decreased by 
`r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'High' & mean.cv.20$survey_freq == 2, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% 
when moving from low to high detection rates at biennial branding (i.e., branding frequency has a stronger effect than detection). Cohort sample size and branding frequency have a greater effect on CV values in scenarios with the 10-year study horizon than the 20-year study horizon where precision is generally higher.  

In examining the probability of the CV being below 0.125 (the threshold used in MMPA permit applications for sea lion branding) across all simulations, we can see the importance of a longer study time horizon and branding frequency. The MMPA permit application benchmark can be achieved reliably (>75%) for juveniles and adults in all scenarios and achieved reliably for younger age classes in scenarios with: (1) annual branding and greater than low detection, (2) biennial branding over a longer study with medium-high detection, or (3) triennial branding over a longer study with larger sample sizes, though the probability for pup survival rates in these instances is still lower (50-75%) (`r figs('cv_thresh_dot', display = 'cite')`). In short, sample size and branding frequency can compensate for other "losses" of information to a degree that increasing detection probability (within the range studied here) cannot. Study length, in this case though, provides the greatest improvements:  the probability of achieving a cv<0.125 for pup survival for a cohort size of N = 100 individuals increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 3 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% by moving from triennial to biennial branding in a 10-yr study whereas it increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 20, 'value_cat'], 2)*100`% when maintaining biennial branding but moving from a 10-yr to a 20-yr study. 

#### Detecting a difference in survival  
The patterns in probability of detecting a difference between the mean survival rates estimated over the study period and a pre-established "baseline" across survey features are similar to those of CV results. Here, however, it is exceedingly important to focus on relative trends, as the reported probabilities are a direct product of the percent difference that is examined - an analytical choice that could easily be modified. As described above, we examined two sets of percent differences: a smaller (15%, 10%, 5%, 2.5% for pups, age-1:2, juveniles, and adults, respectively) and larger (20%, 15%, 10%, 5%) difference between baseline and true data-generating values. Naturally, the probability of detecting a small difference will be lower than that of detecting a large difference, as the inherent uncertainty in survival estimates captured by the posterior distribution would be more likely to overlap with a baseline threshold that is closer to the true data-generating value. We largely report results for scenarios examining data generated with a large difference from a baseline (see Appendix for probabilities of detecting a small difference). 

Overall, the probability of detecting a difference in survival rates varied by age class and notably across branding frequency, cohort size, and study length (`r figs('cri_dot', display = 'cite')`). In a 10-yr study, the probability of detecting a difference is low for adults (<`r max()`) across all scenarios and reaches X-Y in the best-case scenarios (annual branding of 100-200 individuals) for pups and yearlings

This is a lot to look at, but overall, you can see that in order to achieve >80% probability of detecting a change in survival, the most influential survey features are branding schedule, sample size, study horizon, and whether you're interested in detecting a smaller or larger change in survival. 

In the following figures, the above information is filtered for simpler views. Here we can see a clearer picture of the effects of study horizon, sample size, and branding frequency. These results show that a larger change in survival can be reliably detected in a variety of scenarios, including triennial sampling of larger cohorts over a 20-year study. However, if you want to detect a smaller change in survival, annual branding or biennial branding with larger sample sizes and a 20-year study are necessary. 

#### Relative bias  
Relative bias was generally low for all scenarios, though higher relative bias is evident with triennial branding and small sample size. Patterns in bias for survival estimates are less apparent across levels of detection. 

#### RMSE  
RMSE is a combined measure of bias and variance and is generally very low. Model performance in terms of RMSE follows an expected pattern with lowest RMSE in scenarios with annual branding frequency and higher cohort sizes, and particularly the 20-year study horizon. RMSE values are generally higher for age-2 and younger due to the higher variability simulated for their survival rates by design. 
 
### Discussion  
 
- Aims/results/methods review
-- Review most compelling results
-- Summarize benefits/applications/importance
 
- Review other studies that have done this?
-- Example 1
-- Example 2
 
- What it means for SSL  
-- Study design must also consider "risk tolerance" and management goals

-- What are those for SSL? They vary across space (and time as management needs change?)
 
-- Goals have to be re-evaluated in iterative process

- Recommendations for mark-resight designs generally
-- Example 1
 
- Conclusion
-- Benefits and challenges of study
-- Important for future of dwindling funding

### Figures and tables  


```{r cv continuous dot, fig.height = 6, fig.width = 7}

cv_cont_dot

```
Figure 2. Coefficient of variation for age-specific survival rates across survey design features, including branding frequency, branding cohort size, and mark-resight detection probability. 


```{r cv threshold dot, fig.height = 6, fig.width = 8}

cv_thresh_dot

```
Figure 3. Probability of the coefficient of variation for age-specific survival rates being less than 0.125 across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability.



```{r detect change, fig.height = 6, fig.width = 8}

cri_dot

```
Figure 4. Probability of detecting a change in age-specific survival rates across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability.


```{r effort, fig.height = 6, fig.width = 8}

effort_dot

```
Figure 5. Probability of detecting smaller and larger changes in pup survival with successive gains in survey effort (combinations of detection probability and branding frequency) across survey features, including branding cohort size and study horizon. 

### Literature review

Pollock et al. 1990 
- Statistical inference for capture-resight experiments. Wildlife Monographs 107:3â€“97.
- recommends CV < 0.2? (Kristensen & Kovach 2018)

Campbell et al. 2002
- an assessment of monitoring efforts in endangered species recovery plans; a review of 181 species
- were proposed tasks implemented?
- Trend monitoring/abundance most commonly proposed recovery metric, largely because oftentimes recovery has to be initiated in the face of incomplete information and other barriers
- Not always easy to prioritize implementing "monitoring" if other efforts (threat mitigation, captive breeding, habitat restoration) might have more direct effects on abundance
- Species-specific monitoring plans are important 
- Proposed/implemented monitoring generally didn't address threats

Naidoo et al. 2006
- Incorporating costs into conservation planning
- By incorporating spatial distribution of benefits (not all areas provide equal benefits), you get a more efficient and effective outcome per dollar if account for (spatial heterogeneity of) costs
- Types of different costs - numerous
- Barriers: (1) biologists "invented" field of conservation and aren't trained as economists, and (spatially explicit) cost data isn't available, but number of studies are increasing; (2) many conservation plans are just difficult/infeasible to implement; (3) ecologists reluctant to include factors other than biological (economic) in conservation prioritization
- Nice quote: "Balancing research on biodiversity features (i.e. the benefits side) with a greatly strengthened understanding of economic (and indeed other) aspects of the costs side will lead to novel and creative ways to obtain environmental benefits in the most efficient manner possible."

Field et al. 2005
Field, S.A., Tyre, A.J., Possingham, H.P., 2005. Optimizing allocation of monitoring effort under economic and observational constraints. Journal of Wildlife Management 69, 473â€“482.

Nichols & Williams. 2006
- Monitoring for conservation
- Framing comparing to Platt's original criticism of collecting scientific data without clear hypothesis-testing application/goals; likens that to targeted monitoring vs. "omnimbus surveillance monitoring"; define targeted as being "integrated into conservation practice" alongside monitoring design and implementation informed by hypotheses about ecological responses to management actions
- Surveillance often implemented to "learn more about a system", which can be helpful, but doesn't get at effective and efficiency criteria
- Conservation "rooted in decision theory"; the need for making state-dependent decisions (includes confidence about model, quantifying uncertainty, etc)
- Informed decision processes and adaptive management: objectives, management actions, model of response to management action, measure of confidence, and monitoring program that provides estimates of system state
- Understandable that "omnibus" monitoring is so prevalent - could arguably be most versatile as questions arise and cover most species? not arguing fully against it, just that it might not be the most efficient
- Surveillance often triggered by identifying a decline; better if possible to understand best remedy for recovery rather than reason for decline
- Particularly important in a time with limited conservation funding and such widespread conservation need 
- Very nice paper

Field et al. 2007
Field, S.A., Oâ€™Connor, P.J., Tyre, A.J., Possingham, H.P., 2007. Making monitoring meaningful. Austral Ecology 32, 485â€“491. 
- Estimates need to be accurate/precise to be useful/answer the right questions
- Citation for not commonly done?

Taylor et al. 2007
Lessons from monitoring trends in abundance of marine mammals. Marine Mammal Science 23, 157175.
- Failure to plan wastes valuable resources

Lyons et al. 2008
Lyons, J.E., Runge, M.C., Laskowski, H.P., Kendall, W.L., 2008. Monitoring in the context of structured decision-making and adaptive management. Journal of Wildlife Management 72, 1683â€“1692.
- Information should be useful, i.e. affect decision-making; wastes resources if fail to improve the process and miss documenting things you intended to

Reynolds et al. 2011
- Nice intro framing
- Identifying effective and efficient survey designs for monitoring
- Monitoring program only "effective" if it produces info with sufficient accuracy/precision to answer scientific questions and influence decisions
- Generally, speed at detecting a change is important, but resources constrain, so need efficient: quickest detection for lowest cost (*Sims et al. 2008*)
- Effectiveness and efficiency determined by survey design; sampling effort (per survey) and survey frequency main components of this effective-efficient trade-off spectrum
- Despite importance, not often done (Legg & Nagy 2006, Lindenmayer & Likens 2009)
- Risks: resources that could have gone elsewhere are wasted, and program's efficacy/ineffectiveness may be unresolved due to natural variability in the state process, and lose opportunity to have well-defined management objectives, loss of long-term institutional support/funding; can create a "falst sense of management performance", doesn't promote true understanding of costs of (helpful) information
- Planning becomes more important and more complex with increasingly complex observation processes (sources of bias, logistical constraints, multiple sources of variability)
- Applied to brown bears in Alaska
- Management objectives, actions, and information needs

Sollmann et al. 2012
- Black bear data and simulation study; not much discussion about simulation

Torrubia et al. 2014
- Getting most connectivity per conservation dollar; Washington ground squirrel (Urocitellus washingtoni)
- Found that incorporating spatially explicit cost information improved efficiency (reduced overall costs and increase % land restored) of conservation actions
- Very land/terrestrial/connectivity-focused

Sun et al. 2014
- Trap configuration in spatial MR; black bear (ursus americanus)
- Different configurations (spacing and number of traps) work, but highly dependent on home range size
- Varied detection and spatial scaling parameters (how much animal travels relative to home range?)

Peel et al. 2014
- Mark-recapture simulations for acoustic abundance estimates of whales (Antactic blue)
- Lower encounter rates for rare species (line transects and mark-resight)
- Aimed to assist in planning mark-recap surveys for whales (pre-planning side of things)
- Densely detailed information about encounter rates, vocalization/movement assumptions; not a clear explanation of the survey features that they were examining across.... mainly showed that the acoustic assistance improves estimation over mark-recapture alone

Wilton et al. 2014
- Trap precision configuration influences black bear density/abundance estimation
- Mainly tested bias under proposed study designs, but found that situations with low density and non-uniform distribution required more thoughtful trade-offs about snare spacing, coverage, and sample sizes to achieve precision

Johnston et al. 2015
- Abundance models (compared to occupancy) improve spatial and temporal prioritization of conservation resources; not a simulation study, probably don't need to cite

Peel et al. 2015
- Same study/issue as above, better citation - more focused on study design
- Estimates of abundance have to be appropriately precise to be useful (Reynolds et al 2011)
- Marine mammal surveys (particularly for dispersed and remote areas) can be challenges and expensive (Williams and Thomas 2009), making planning really important to make sure resources aren't wasted
- CV across true mortality, sex ratio, model, and growth rates, and survey features (number of vessels, survey length, distribution of effort)
- Pre-survey planning simulations are important to ensure that investment meets desired precision and is able to answer the questions being asked

Yackulic et al. 2015
- Modeled species interactions and simulated different underlying state processes to examine when bias might be an issue (citation for examining specific situation rather than using to design study beforehand)

Burton et al. 2015
- Linking camera trapping to ecological processes; review study examining number of papers not accounting appropriately for all the potential biases given ecological processes, but good citation for proliferation/adoption of camera trapping technology

Lyons et al. 2015
- Superpopulation size, proportion marked, and number of animals sampled (stopover duration for red knot sandpipers; Calidris canutus roselaari)
- Relative bias less affected by number of birds per scan sample or superpopulation size
- Accuracy (as measured by RMSE) improved with more scans per day and with larger scan sample sizes; same with CV

Evans et al. 2016. 
- Species recovery in the United States: increasing the effectiveness of the ESA
- Insufficient funding for species recovery, and not proportional across taxa (mostly for fish; salmon/sturgeon)
- Funding shortages bring trade-offs front and center; allocations more often driven by political/social factors
- Mitigations necessary for climate change will likely further constrain recovery resources
- Limited resources often preclude adaptive management feedback applications
- Hard to know how often/if the agencies follow their own prioritization scheme for allocating recovery funds

Galvez et al. 2016
- Incorporating costs into camera trap surveys
- "Paucity of research examining how to allocate survey effort to optimize estimation that takes into account operational costs"
- Incorporate costs per sampling unit, then look across survey lengths and number of cameras needed to achieve precision targets given detection/occupancy scenarios
- Generally more cost-efficient to do multiple camera traps over fewer occasions because travel/salaries are big part of costs, particularly for elusive species

Gonzalez et al. 2016
- UAVs and AI monitoring for the future

Lanier et al. 2016
- Effects of survey design on demography, simulation for frogs, open robust design
- Synchronous vs. asynchronous breeding, logistical access (whether breeding grounds can be surveyed)
- Fairly large range of bias in survival across scenarios

Little et al. 2016
- trade-offs for cost-constrained fisheries management
- lots of lists of all the different "risks" that incur more costs (e.g., the need to implement a control rule for additional cost)
- risk (of overfishing)-catch-cost frontier.... easier to derive benefits for fisheries compared to wildlife monitoring

Sackett & Catalano 2017
- Red snapper (Lutjanus campechanus) in GoM; recreational fishing mortality; sample size (number tagged), fishing effort, fish density, tag loss - lots of facets
- Results included "most cost effective study design"
- High vs. variable reward fish tags
- Precision improved with increasing sample sizes, but so does costs
- Lots of details testing specific study designs
- Have to consider incentive vs. reporting rate

Armsworth et al. 2017
- Argue that factoring in economic costs doesn't *always* improve efficiency - sometimes can exacerbate disagreements about priorities.... still have to be very specific about protection efforts and how to quantify benefits
- Disagreements are worst when benefits data are more variable
- Benefits of accounting for cost are more variable when cost data are more variable
- Simulation approach

Del Vecchio et al. 2018
- Trade-offs between effort and data quality - habitat monitoring
- Plot sampling schemes; meh

Kristensen & Kovach 2018
- SECR and new england cottontail (Sylvilagus transitionalis)
- Studies are less common for smaller individuals; conclude optimal study designs will vary among organisms (habitat use and spatial extent), so pilot planning is important
- *Campbell et al. 2002* abundance is the most common quantitative metric in recovery plans and delisting criteria, key parameter underlying extinction risk
- *Need good abundance estimates to measure response to management actions (Nichols & Williams 06; Johnston et al. 2015)*
- CV and relative bias; number of survey occasions, pellet collection spacing, true density, transect spacing all important predictors; number of survey occasions less impactful?
- "When detectability was low (g0 = 0.1), both additional detectors and more frequent sampling were required to achieve the desired levels of precision than with higher detectability (g0 = 0.2)"
- *Pollock et al 1990* recommends CV < 0.2? 
- Also found that true density had large effect on performance, had to compensate for low density by upping observation metrics
- Nice examples of when management goals affect needed precision: tracking fate of reintroduction (maybe need to ensure less bias and higher precision) compared to responses to habitat management (number alive with low precision acceptable?)

Durden et al. 2021
- Bottlenose dolphine (Tursiops truncatus truncatus) in Indian River Lagoon
- Robust design and survey optimization simulation; limited description of results - mainly validating their design - checking precision; but also looking for ways to reduce survey effort without losing precision, and suggest importance of long-term planning

Freeman et al. 2021
- SECR on small mammals; number of trapping occasions, trap number - both metrics improved estimation; salt marsh harvest mouse (Reithrodontomys raviventris)

White et al. 2022
- Decision support framework for assessing costs and benefits of conservation actions
- Need for incorporating costs, but difficult to estimate and poorly/infrequently reported and therefore rarely studied
- Mainly a how-to


### Literature cited



### Appendix  
More sample sizes, more facets. 

```{r CV heatmap all facets, fig.height = 6, fig.width = 8, eval = F}

cv_heat_cont

```
Figure S1. CVs across all sample sizes and survey features.

```{r CV threshold heatmap all facets, fig.height = 6, fig.width = 8, eval = F}

cv_thresh_heat

```
Figure S2. Probability of meeting CV threshold across all sample sizes and survey features.

```{r change all facets, fig.height = 7, fig.width = 9}

cri_all_cont_heat

```
Figure S3. Probability of detecting change in survival across all sample sizes and survey features. 

```{r bias app, fig.height = 5, fig.width = 7}

bias_heat
bias_dot

```
Figure S4. Relative bias (%). Heat vs. dot?


```{r RMSE app, fig.height = 5, fig.width = 7}

rmse_heat
rmse_dot

```
Figure S5. RMSE. Heat vs. dot? 

