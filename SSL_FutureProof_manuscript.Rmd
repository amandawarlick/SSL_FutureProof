---
title: "SSL Future Proof Project Update - Jan 2023"
output: html_document
---

```{r setup, include=FALSE, fig.align = 'center'}

knitr::opts_chunk$set(echo = FALSE, eval = T, message = F, warning = F, fig.align = 'center')

library(here) #v1.0.1
library(dplyr) #v1.0.5
library(nimble) #v0.12.1
library(coda)
library(ggh4x)
library(readr)
library(knitr)
library(Hmisc)
library(stringr)
library(captioner)

#functions to use for calling figures/tables
figs <- captioner(prefix = "Figure")
tbls <- captioner(prefix = "Table")

source(here::here('scripts', 'PlotTheme.R'))

```

```{r scenarios and convergence}

sc <- c(1:45)

scenarios <- data.frame(scenario = c(sc),
                        survey_freq = c(rep(1,15), rep(2,15), rep(3,15)),
                        detection = c(rep(c('Low', 'Low', 'Low', 'Low', 'Low',
                                            'Med', 'Med', 'Med', 'Med', 'Med', 
                                            'High', 'High', 'High', 'High', 'High'), 3)),
                        N = c(rep(c(50,75,100,150,200), 9)))


#for figure legends
phi_pars <- c('phi[P]','phi[1]', 'phi[2]', 'phi[J]', 'phi[A]')
p_pars <- c('p[1]', 'p[2]', 'p[J]', 'p[A]') 
freq_labels <- c('1' = 'Annual', '2' = 'Biennial', '3' = 'Triennial')
occ_labels <- c('5' = '5 yrs', '10' = '10 yrs', '15' = '15 yrs', '20' = '20 yrs')

```


```{r cv}

#load in results for 10-yr study horizon
cv.files7 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv7', all.files = FALSE, full.names = F)

cv.files8 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv8', all.files = FALSE, full.names = F)

cv.files9 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv9', all.files = FALSE, full.names = F)

cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files12 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv12', all.files = FALSE, full.names = F)

cv.files <- c(cv.files7, cv.files8, cv.files9, cv.files10, cv.files11, cv.files12)


cv <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv <- rbind(cv, temp)

} #rds file

cv <- cv %>%
  filter(rhat < 1.1) 

mean.cv <- data.frame(cv) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

mean.cv.thresh <- data.frame(cv) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)

#load in results from 20-yr study and merge
cv.files10 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv10', all.files = FALSE, full.names = F)

cv.files11 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv11', all.files = FALSE, full.names = F)

cv.files14 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv14', all.files = FALSE, full.names = F)

cv.files15 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv15', all.files = FALSE, full.names = F)

cv.files18 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv18', all.files = FALSE, full.names = F)

cv.files19 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv19', all.files = FALSE, full.names = F)

cv.files22 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'),
                         pattern = 'cv22', all.files = FALSE, full.names = F)

cv.files23 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv23', all.files = FALSE, full.names = F)

cv.files26 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv26', all.files = FALSE, full.names = F)

cv.files27 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv27', all.files = FALSE, full.names = F)

cv.files30 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv30', all.files = FALSE, full.names = F)

cv.files31 <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'cv31', all.files = FALSE, full.names = F)


cv.files <- c(cv.files10, cv.files11, cv.files14, cv.files15, cv.files18, cv.files19,
              cv.files22, cv.files23, cv.files26, cv.files27, cv.files30, cv.files31)

cv.20 <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv.20 <- rbind(cv.20, temp)

} #rds file

cv.20 <- cv.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) #%>%
  # bind_rows(cv)

mean.cv.20 <- data.frame(cv.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 20) %>%
  bind_rows(mean.cv)

### figures

## continuous dotplots
dotplot_dat_mean <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_up <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(upper = quantile(value, probs = 0.975)) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat_low <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(lower = quantile(value, probs = 0.025)) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable))

dotplot_dat <- dotplot_dat_mean %>%
  merge(dotplot_dat_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_dat_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection')

#study horizon
cv_cont_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_errorbar(aes(ymin = lower, ymax = upper, x = survey_freq), width = 0.1) +
  xlab('Branding frequency') + ylab('CV') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')


##threshold approach

#dotplot 
dotplot_dat <- cv.20 %>% transform(length = 20) %>% 
  bind_rows(cv %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  transform(value_cat = value<0.125) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), labels = c('Low', 'Medium', 'High'))) %>%
  #filter out detection params
  filter(!is.na(variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection')

#no quantile error bars on yes/no 
cv_thresh_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = survey_freq, y = value_cat, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Probability of cv < 0.125') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

###appendix figures -- none unless want all sample sizes shown

##continuous cv
plot_dat <- mean.cv.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_heat_cont <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "cv",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##threshold

#heatmaps
mean.cv.thresh.20 <- data.frame(cv %>% transform(length = 10)) %>% 
  bind_rows(cv.20 %>% transform(length = 20)) %>%
  transform(value_cat = value<0.125) %>%
  group_by(variable, scenario, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value_cat = mean(value_cat), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'), 
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size')

plot_dat <- mean.cv.thresh.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

cv_thresh_heat <- ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') + ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of \n cv < 0.125",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


```


```{r detecting change}

#load in results from 10-yr
cri.scenarios <- c('dec_little', 'dec_big')
append <- c(5,10)

cri.all <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -5,-5)) %>%
  transform(length = append[a]) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all <- rbind(cri, cri.all)

} #rds file
} #j


mean.cri <- data.frame(cri.all) %>%
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') 

#load in results from 20-yr
cri.all.20 <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop', 
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -6,-5)) %>%
  transform(length = append[a]+10) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all.20 <- rbind(cri, cri.all.20)

} #rds file
} #j

mean.cri.20 <- data.frame(cri.all.20) %>%
  #are these just all the unfinished/unfilled sim dataframe rows? 
  filter(!is.na(value)) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  bind_rows(mean.cri)

#plots

#dotplot

dotplot_dat <- cri.all.20 %>% filter(length == 20) %>% 
  bind_rows(cri.all %>% filter(length == 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N, threshold) %>%
    dplyr::summarize(value = mean(value, na.rm = T), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

cri_dot_big <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) & length %in% c(10,20)
                               &  threshold == 'dec_big'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Probability of detecting larger difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

cri_dot_small <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) & length %in% c(10,20)
                               &  threshold == 'dec_little'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Probability of detecting small difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

#appendix figures

#all facets
plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & change size', 
            samp_size = 'Sample size & study length')

#all facets continuous
cri_all_cont_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
        strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#all facets categorical
cri_all_cat_heat <- ggplot(plot_dat %>% filter(length %in% c(10,20)),
       aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting difference in survival",
                    # values = c('firebrick3', 'orange', 'steelblue2'))
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))

#fewer facets
 plot_dat <- mean.cri.20 %>% filter(grepl('phi', variable) & length %in% c(10,20)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big'),
                               labels = c('Small difference', 'Large difference'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size')
 
#big decrease in survival 
cri_big_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')), 
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of detecting difference in survival",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) 

#categorical, small decrease
cri_big_cat_heat <- ggplot(plot_dat %>% filter(threshold %in% c('Large difference')),
       aes(x = factor(detection), y = variable, fill = value_cat), alpha = 0.3) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting small change",
                    values = c('salmon', 'lightgoldenrod2', 'lightskyblue2'))

#more years (5, 10, 15, 20)
dotplot_dat <- cri.all.20 %>%  
  bind_rows(cri.all) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N, threshold) %>%
    dplyr::summarize(value = mean(value, na.rm = T), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

cri_dot_app <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200) &  threshold == 'dec_big'),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Probability of detecting difference in survival') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')



```

```{r collapsed detecting change}

#mean.cri.20 contains the mean probability (across simulations) where the cv < 0.125.

#values for the scenario with the "least" amount of contributing information
#i.e., triennial sampling, N = 50, 10 years, low detection (scenario 31)

cri_least_info <- mean.cri.20 %>% transform(samp_size = 'Sample size') %>%
  dplyr::select(!survey_frequency) %>%
  filter(detection == 'Low' & length %in% c(10,20) &
           survey_freq == 3 & N %in% c(50, 100, 200)) %>%
  dplyr::select(c(variable, N, value, length, threshold)) %>%
  dplyr::rename(min_val = value)

cri_delta <- mean.cri.20 %>% filter(length %in% c(10,20)) %>%
    filter(N %in% c(50, 100, 200)) %>% 
  merge(cri_least_info, by = c('variable', 'N', 'length', 'threshold')) %>%
  transform(delta = value-min_val) %>%
  transform(det_cat = as.numeric(factor(detection)),
            N_cat = as.numeric(factor(N))) %>%
  # filter(variable == 'phiP') %>%
  filter(variable %in% c('phiP', 'phi1')) %>%
  transform(survey_cat = 4-as.numeric(factor(survey_freq))) %>%
  transform(step = N_cat + survey_cat + det_cat) %>%
  transform(step = ifelse(detection == 'Low' & survey_freq == 3, 0, step))

cri_delta_steps <- cri_delta %>% 
  # filter(N == 50 & variable == 'phiP') %>%
    filter(variable %in% c('phiP', 'phi1')) %>%
  transform(category = ifelse(step == 0, 'Baseline', 
                  ifelse(det_cat > 1 & survey_cat == 1, 'Detection only',
                  ifelse(survey_cat > 1 & det_cat == 1, 'Frequency only', 'Detection & frequency')))) %>%
  transform(step = ifelse(step == 0, 0,
                          ifelse(det_cat == 1 & survey_cat == 1, NA,
                            ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 1 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 1 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 1 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 1, 2, 
                            ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 2 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 2 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 2 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 2, 2, 
                            ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 2 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 2 |
                              survey_cat == 2 & N_cat == 3 & det_cat == 2, 1,
                          ifelse(category == 'Detection only' & N_cat == 3 & det_cat == 3 | 
                            category == 'Frequency only' & N_cat == 3 & survey_cat == 3 |
                              survey_cat == det_cat & N_cat == 3, 2, 
                            ifelse(det_cat == 1 & survey_cat == 1, NA, NA)))))))))) 

scenario_fill_cri <- expand.grid(step = 0,
              length = c(10,20),
              threshold = c('dec_little', 'dec_big'),
              N = c(50, 100, 200),
              category = c('Detection only', 'Frequency only', 
                                         'Detection & frequency')) %>%
  merge(cri_delta_steps %>% dplyr::select(length, threshold, min_val, category, variable, N), 
        by = c('category', 'N', 'length', 'threshold')) %>% 
  distinct() %>%
  dplyr::rename(value = min_val)
                            
effort_dat <- cri_delta_steps %>%
  dplyr::select(category, N, length, threshold, step, value, variable) %>%
  bind_rows(scenario_fill_cri) %>%
  filter(category != 'Baseline') %>%
  transform(threshold_name = factor(threshold, levels = c('dec_little', 'dec_big'), 
                                    labels = c('Small difference', 'Large difference'))) %>%
  transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Branding frequency only', 'Detection & branding frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High')))

#probability of detecting change.... 
effort_dot <- ggplot(effort_dat %>% filter(!is.na(step)) %>% filter(variable == 'phiP') %>%
         transform(samp_size = 'Sample size & study length') %>%
         transform(length = factor(length, labels = c('10 yrs', '20 yrs'))), 
       aes(factor(step), value, group = category, col = category)) +
  # geom_point(position = position_dodge(width = 0.1)) +
  geom_point() +
  geom_line() +
  geom_hline(aes(yintercept = 0.75), linetype = 'dotted') +
  facet_nested(threshold_name~samp_size+length+N) +
  xlab('Survey effort (detection + branding frequency)') + 
  ylab('Probability of detecting difference in pup survival') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_color_manual(values = rainbow2[-c(1,4,6)], name = '')


text_dat <- cri_delta_steps %>%
  distinct(category, det_cat, survey_cat, step) %>%
  transform(inc = ifelse(det_cat == 2 & survey_cat == 3 | det_cat == 3 & survey_cat == 2, 'n', 'y')) %>%
  filter(inc == 'y') %>%
  dplyr::select(-inc) %>%
   transform(category = factor(category, levels = c('Baseline', 'Detection only', 
                                 'Frequency only', 'Detection & frequency'),
                              labels = c('Baseline', 'Detection only', 
                                 'Branding frequency only', 'Detection & branding frequency'))) %>%
  transform(step = factor(step, levels = c(0,1,2), labels = c('Low', 'Medium', 'High'))) %>%
  transform(det_cat = factor(det_cat, labels = c('Low', 'Medium', 'High')),
            survey_cat = factor(survey_cat, labels = c('Triennial', 'Biennial', 'Annual')))

effort_grid <- ggplot(text_dat %>% filter(category != 'Baseline'), aes(det_cat, survey_cat, fill = category)) +
  geom_tile(data =  text_dat %>% filter(category != 'Baseline'), 
            color = "white", lwd = 1.5) +
  geom_tile(data = text_dat %>% filter(category == 'Baseline'), 
            fill = 'slateblue4', color = "white", lwd = 1.5, show.legend = F) +
  geom_text(aes(label = step), fontface = 'bold') +
  # geom_text(data = text_dat %>% filter(category == 'Baseline'),
  #           aes(label = step), show.legend = F) +
  annotate('text', x = 1, y = 1, label = 'Low', fontface = 'bold') +
  ylab('Branding frequency') + xlab('Detection') +
  theme_bw() +
  theme(legend.position = 'top',
        panel.grid.major = element_blank(),
        axis.text.y = element_text(angle = 90, hjust = 0.5),
        axis.title.x = element_text(vjust = -1),
        axis.title.y = element_text(vjust = 2)) +
  scale_fill_manual(values = c(rainbow2[-c(1,4,6)]), name = '')


# effort_plot <- plot_grid(effort_dot, effort_grid, labels = c('(a)', '(b)'))



```


```{r relative bias}

bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias <- rbind(rel.bias, temp)

} #rds file

rel.bias <- rel.bias %>%
  filter(rhat < 1.1) %>%
  transform(length = 10)

mean.rel.bias <- data.frame(rel.bias) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', samp_size = 'Sample size') %>%
  transform(length = 10)


bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias.20 <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias.20 <- rbind(rel.bias.20, temp)

} #rds file

rel.bias.20 <- rel.bias.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20)

mean.rel.bias.20 <- data.frame(rel.bias.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rel.bias) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3), 
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and sample size') 

#figures
#heatmaps
plot_dat <- mean.rel.bias.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) 


bias_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
       aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Branding frequency') + ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(length = occ_labels),
             scales = 'free_x') +
  scale_fill_gradient2(name = "Relative bias (%)",
                      mid = "#FFFFFF", low = "deepskyblue1", high = "red2", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#dotplots
dotplot_mean <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(value = mean(value)*100, .groups = 'keep') 

dotplot_low <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(lower = quantile(value*100, probs = 0.025), .groups = 'keep')

dotplot_up <- rel.bias.20 %>% transform(length = 20) %>% 
  bind_rows(rel.bias %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
    dplyr::summarize(upper = quantile(value*100, probs = 0.975), .groups = 'keep')

dotplot_dat <- dotplot_mean %>% 
  merge(dotplot_up, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  merge(dotplot_low, by = c('length', 'variable', 'detection', 'survey_freq', 'N')) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(det = 'Detection', samp_size = 'Study horizon and sample size') %>%
  #filter out detection params
  filter(!is.na(variable))

bias_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  # geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 0), linetype = 'dotted') +
  xlab('Branding frequency') + ylab('Relative bias') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +

  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')


```

```{r RMSE}

rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse <- rbind(rmse, temp)

} #rds file

rmse <- rmse %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 10)

mean.rmse <- data.frame(rmse) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Branding frequency & study length', 
            samp_size = 'Sample size') %>%
  transform(length = 10) 


rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims', 'prePop'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse.20 <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 'prePop',
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse.20 <- rbind(rmse.20, temp)

} #rds file

rmse.20 <- rmse.20 %>%
  filter(rhat < 1.1) #%>%
  # transform(length = 20) 

mean.rmse.20 <- data.frame(rmse.20) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(length = 20) %>%
  bind_rows(mean.rmse) %>%
  transform(survey_frequency = 'Branding frequency & study length', 
            samp_size = 'Study horizon and sample size', det = 'Detection') %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial')))


#plots
plot_dat <- mean.rmse.20 %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

rmse_heat <- ggplot(plot_dat %>% filter(N %in% c(50,100,200)), 
                    aes(x = survey_freq, y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Branding frequency') +
  ylab('Parameter') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T, 
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "RMSE",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "black"),
        legend.text = element_text(size = 10, vjust = 0.5),
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = "black", size = 10),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

##dot plots
dotplot_dat <- rmse.20 %>% transform(length = 20) %>% 
  bind_rows(rmse %>% transform(length = 10)) %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(length, variable, detection, survey_freq, N) %>%
  # dplyr::summarize(value = mean(value),
  #                  lower = quantile(value, probs = 0.025),
  #                  upper = quantile(value, probs = 0.975),
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'),
                              labels = c('Pup', 'Age-1', 'Age-2', 'Juvenile', 'Adult'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'),
                               labels = c('Low', 'Medium', 'High'))) %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial'))) %>%
  transform(survey_frequency = 'Branding frequency', samp_size = 'Study horizon and sample size',
            det = 'Detection') %>%
  #filter out detection params
  filter(!is.na(variable))

rmse_dot <- ggplot(dotplot_dat %>% filter(N %in% c(50, 100, 200)),
       aes(x = factor(survey_freq), y = value, col = factor(variable), group = variable)) +
  geom_point() + geom_line() +
  xlab('Branding frequency') + ylab('RMSE') +
  facet_nested(det + detection ~ samp_size + length + N, drop = T,
             labeller = labeller(survey_freq = freq_labels, length = occ_labels),
             scales = 'free_x') +

  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[-c(1,4,6)], name = 'Survival rate')

```

Title: 
- Mark-resight survey design optimization 

Authors: Amanda J. Warlick, Peter Mahony, Brian Fadely, Sharon Melin, Tom Gelatt, Kim Raum-Suryan, Sarah J. Converse

Target journal: Journal of Wildlife Management; Marine Mammal Science

### Abstract

### Introduction    

Knowledge about vital rates, population dynamics, and trends in abundance are essential for wildlife conservation and management. However, this information can be difficult to obtain at the level of precision that is useful for answering pressing management questions or developing meaningful and achievable conservation targets. For a depleted or declining population, the ideal survey design would be one that would be able to facilitate detecting a change in population status most expediently. However, funding limitations in natural resource and wildlife fields dictate that the ideal survey design be both effective and efficient, delivering the quickest (and most precise) possible answers at the lowest cost (Field et al. 2005, Reynolds et al. 2011). In addition to cost, it may be invasive, disruptive, or logistically challenging to obtain data at the level of precision that is required to address monitoring objectives, particularly for small, declining, or remote populations. It is therefore critically important to develop wildlife monitoring programs that optimize the trade-offs between survey effort (and the resulting quality of information obtained) and survey cost for a given wildlife species, population, or habitat location of interest. Unfortunately, statistical power analyses or simulation analyses that inform choices about survey design are seldom conducted before monitoring programs are implemented, potentially leading to wasting valuable and limited funding resources, lost opportunities for implementing adaptive management, reduced public trust, and perpetuating underperforming monitoring programs. 

Wildlife monitoring programs are often focused on tracking trends in abundance or vital rates that can inform status assessments, track progress toward recovery goals, or lend insight into the effects of environmental variability or anthropogenic stressors on population dynamics or extinction risk. When monitoring plans fail to meet these kinds of monitoring objectives, practitioners risk incorrectly declaring that a species or population does not meet an established criteria for management intervention, or conversely investing in developing additional mitigation measures that were not in fact warranted. Similarly, without sufficiently precise population monitoring data, resource managers could fail to detect that an allowable take level was exceeded for a threatened species, or overly restrict other resource uses if a mortality or take level was overestimated. In these contexts, imperfect detection during observations of complex ecological processes leads to varying degrees of uncertainty about the underlying processes (i.e., vital rates, environmental effects) or quantities (i.e., abundance, trends) of interest. This degree of uncertainty (and level of precision or bias in parameter estimates) is largely determined by survey effort, which often comprises multiple factors, including but not limited to the number of surveyed sites, the number of repeat surveys, the number of surveyed or marked individuals, and the duration of the study. All of these features have distinct advantages and cost profiles that are entirely dependent on the context of the study, including the life history characteristics of the species, the habitat, the conservation status, and monitoring objectives (Taylor et al. 2007).  

Despite the importance of developing effective and efficient monitoring plans, numerous barriers often prevent wildlife practitioners from rigorously and statistically examining the trade-offs between survey effort, data quality, monitoring objectives, and costs prior to initiating a monitoring program. These barriers can arise from institutional, logistical, or even ecological situations. First, funding for wildlife monitoring programs often fluctuates over time (due to political regimes or change in a population's conservation status) and allocations may not come at predictable intervals or in sufficient amounts to afford additional time for simulation analyses that inform survey design. Additionally, monitoring costs may be difficult to quantify in such a way as to directly relate to demographic estimation (e.g., costs are more easily aggregated per field technician or per survey trip as opposed to being able to apportion costs per individual animal marked, nest surveyed, number of observation days, etc.). Monitoring costs may also be unpredictable due to logistical challenges of safely and consistently surveying dynamic or remote locations. Second, expertise to conduct such analyses may also be lacking. Third, poorly defined monitoring objectives that lack specific quantitative metrics makes conducting pre-survey design studies challenging, as there may not be a specified quantity of interest to "optimize". Nebulous monitoring objectives often perpetuate ongoing "surveillance" monitoring, which certainly can lead to improved insights about species and ecological processes, but is likely not the most efficient use of resources (Nichols & Williams 2006). These situations can arise when risk tolerances for making incorrect conservation decisions is difficult to elicit or quantify across diverse stakeholders. Due to these and other barriers and constraints, simulation studies are most often conducted *post-hoc* to validate model results by confirming that the survey protocol used for a given study generally produces asymptotically unbiased estimates or achieves a reasonable level of precision (Lyons et al. 2015, Yackulic et al. 2015, Himes Boor et al. 2023). 

In this study, we present a simulation analysis that examines parameter precision and the ability to detect a change in age-specific survival probabilities across a range of survey features estimated in a mark-resight model framework. The aim of this work was to inform the design of ongoing and future monitoring surveys for Steller sea lions (*Eumetopias jubatus*) across the species' range, though the concepts and framework apply to other species or populations where mark-resight data are collected for the purpose of detecting demographic trends. Steller sea lion abundance declined considerably throughout the 1970-80s's, leading the species to be listed as Threatened under the Endangered Species Act (ESA). The species was subsequently divided into eastern and western distinct population segments (eDPS and wDPS, respectively), with rookeries in the eDPS (ranging from northern California into southeast Alaska) showing signs of stable and recovering populations and ultimately being delisted in 2013. In the wDPS (ranging from the Gulf of Alaska across the Aleutian Islands into Russia) has shown divergent abundance trends, with abundance at rookeries to the east of Samalga Pass being stable or increasing while those to the west of Samalga Pass have continued to decline, motivating a plethora of research aimed at understanding these trends. Designing a comprehensive, effective, and efficient monitoring program for Steller sea lions is foundational for ongoing efforts to understand demographic and environmental drivers of population dynamics and the divergent abundance trends that have been observed across the species' range in a cost effective way that maximizes the utility of limited available resources. However, this effort is complicated by the diverse landscapes, varying rookery breeding population sizes, and abundance trends across the species range. For rookeries in the eDPS where trends are stable or increasing, monitoring priorities include X and constraints include Y. In contrast, for rookeries in the wDPS where trends are varied, monitoring priorities are X and constraints include Y. 

- Even if it is hard, it is worth doing
-- Benefits for SSL
-- Conclusion sentence

### Methods  

#### Data simulation and model description    
Mark-resight data were simulated over 10- and 20-year study horizons based on basic sea lion life history characteristics. Age class-specific survival and detection probabilities used as data-generating "true" values were based on empirical estimates from individuals branded, released, and resighted in the eastern DPS from 2001-2019. Temporal variance in survival probabilities was simulated based on the mean and standard deviation of age class-specific empirical estimates. Detection probabilities were assumed constant for each age class over the study period. Simulated data were fit to a Cormack Jolly Seber (Cormack 1964,) mark-resight model framework to estimate survival of five age classes (pups, age-1, age-2, juveniles (ages 3-4), and adults 5+) with true ecological states defined by an individual's age. The state process model,

\begin{equation}
z_{i,t} | z_{i,t-1} \sim ~ \text{categorical}(\Omega_{z_{i,t-1},i,t-1}) 
\end{equation}

describes the state *z* of individual *i* at occasion *t*, conditional on the individuals state at the previous occasion, modeled as categorically distributed according to transition array $\Omega$, which is composed of age group-specific survival probabilities ($\phi_\text{i,t}$). Fecundity was not of interest in this analysis and was therefore not incorporated into study design. Temporal variance in survival probabilities was modeled using penalized complexity priors (Simpson et al. 2017, van Erp et al. 2019), where for demographic rate parameter $\gamma$, 

\begin{equation}
\text{logit}(\gamma_\text{a,t}) = \mu_\text{a}^{\gamma} + \epsilon_\text{a,t}^{\gamma}   
\end{equation}

\begin{equation}
\epsilon_\text{a,t}^{\gamma} \sim \text{normal}(0, \sigma_\epsilon)
\end{equation}

\begin{equation}
\sigma_\epsilon \sim \text{exponential}(1) 
\end{equation}

where $\mu_\text{a}^{\gamma}$ is an age (*a*)-specific intercept estimated with back-transformed uninformative priors U(0,1) on the logit scale. $\epsilon_\text{a,t}^{\gamma}$ is an annual (*t*) random effect estimated with a normal distribution with mean zero and standard deviation estimated with a fixed shrinkage rate of exponential(1). This approach reduces the coefficient $\epsilon_\text{a,t}$ toward zero in the absence of strong support for an effect and can improve parameter estimability (Simpson et al. 2017).  

The observation process model included age class-specific observations of individuals based on detection probabilities that were assumed to be constant over the study period:

\begin{equation}
y_{i,t} | z_{i,t} \sim ~ \text{categorical}(\Theta_{z_{i,t} i,t})  
\end{equation}

where observations $y_\text{i,t}$ conditional on the true state $z_\text{i,t}$ are categorically distributed with probability array $\Theta$, which is composed of an individual's detection probability at time *t*, $p_\text{i,t}$. The typical set of mark-recapture model assumptions applied, where it was assumed that branding did not affect detection probability, that survival of individuals was independent, there were no identification errors, mortality during the sampling season was negligible, and that there was no unmodeled heterogeneity in survival and detection probabilities.
 
#### Simulation scenarios  
The above model was fit across 90 scenarios composed of all combinations of branding cohort sizes (N = 50, 75, 100, 150, 200), branding frequency (annual, biennial, triennial), study horizon (10 years versus 20 years), and detection rates (low, medium, high). Detection rates varied by age group, with low and high levels set at +/- 20% of the age-specific empirical estimates (e.g., detection rate levels were 0.48, 0.6, 0.72 for age-1:2; 0.56, 0.7, 0.84 for juveniles; and 0.64, 0.8, 0.96 for adults). Resighting effort was assumed to occur annually regardless of branding schedule due to the increasing feasibility and use of remote cameras for this and other wildlife populations (Burton et al. 2015). As we were not able to quantify the monetary costs of survey effort per individual sea lion branded or resighted to develop a robust cost-benefit optimization scheme across all survey features, we also examined model performance across a collapsed survey "effort" metric (specific combinations of branding frequency and detection probability levels) to highlight which might yield the best model performance. The levels of this survey effort metric were "low" (triennial branding and low detection probabilities), "medium" representing one step of increased effort (biennial branding with low detection, medium detection with triennial branding, or medium detection and biennial branding), and "high" representing two steps of increased effort (annual branding and low detection, high detection and triennial branding, or annual branding and high detection) (`r figs('effort_grid', display = 'cite')`). Annual branding may be unrealistic at most rookeries for Steller sea lions (disturbance and MMPA permit limitations, cost and logistics of surveying remote rookeries, etc.), but is included here as a point of comparison to the other branding frequency schedules and because it may likely be of interest to other wildlife populations or circumstances. Additionally, certain comparisons in the results section are highlighted based on the fact that branding cohort size may not be a survey feature that practitioners can easily modify (rookery size, number of consecutive visits to rookery, etc.). 
 
#### Model performance and fitting     
We assessed model performance across four metrics: coefficient of variation (CV; $\frac{\sigma}{\mu}$), the probability of detecting a change in survival rates, relative bias ($\frac{(\bar{e_{i}}-t)}{t}*100$), and root mean square error (RMSE; $\sqrt{\text{E}[(\bar{e_i}-t)^2]}$). The CV is a useful metric for understanding precision or the degree of dispersion around the mean that is used in MMPA permit applications for the sea lion branding program. Relative bias is a measure of whether estimates are systematically over- or under-estimated relative to the true data-generating value and RMSE is a combined measure of variance and bias. 

To examine the probability of detecting a difference between estimated survival rates and a "baseline" rate, we generated annual survival estimates using a logit normal distribution with a mean rate equal to the empirical mean multiplied by an age-specific percent difference and a standard deviation equal to that of the empirical eDPS estimates. We then examined the probability of whether the credible intervals for each survival rate excluded the original "baseline" rate (at 5, 10, 15, and 20 years into the study). We examined the probability of detecting a "smaller" decrease in survival (15%, 10%, 5%, 2.5% for pups, age-1:2, juveniles, and adults, respectively) versus a "larger" decrease in survival (20%, 15%, 10%, 5%). For example, suppose we estimate a long-term average pup survival rate of 0.55 and are interested in ascertaining the survey features with a high probability of detecting a true survival rate that is 20% (larger decrease) lower than that baseline. In this case, $\phi^{\text{p}}_{\text{sim}} = {\text{lnorm}}(0.55-0.55*0.20, \sigma_\phi^{\text{p}})$ and we recorded whether the upper limit of the 95% credible interval was less than or equal to 0.55 for each simulated dataset. These values were chosen losely based on the apparent age-specific variability in empirical survival estimates for the eDPS. It is important to note that this approach does not aim to detect a *trend* in survival estimates nor does it convey information about *when* a change occurred, just that we can be 95% confident that the mean survival rate over the entire study period (10 or 20 years) excludes a previous "baseline" rate or benchmark of interest.   

For each scenario, 100 unique datasets were simulated and fit using NIMBLE (NIMBLE Development Team 2019) within the R programming environment (R Core Development 2020) using three Markov chain Monte Carlo (MCMC) chains with 20,000 iterations, 10,000 burn-in, and a thinning rate of 3, resulting in 10,000 MCMC samples. Convergence was evaluated using visual inspection of MCMC chains and the Brooks-Gelman-Rubin statistic (Gelman & Rubin 1992; Brooks & Roberts 1998) $\hat{R}$ < 1.1. The proportion of simulations where all parameters converged was high (~95%), though convergence was a bit lower for some scenarios. 

### Results  

Model performance is detailed for each metric below, but was generally consistent across all metrics of precision and bias. In general, model performance degrades most notably across branding frequency, branding cohort size, and study time horizon. In terms of deriving accurate and unbiased estiamtes of a mean survival probability, precision goals stated in MMPA permits can be reliably achieved for all age classes with either a 20-year study horizon or annual branding. The probability of detecting a change in survival varies considerably across simulation scenarios and highlights the power of increasing branding frequency and cohort sample sizes if detecting a change in survival is a high research priority (as opposed to just having precise mean survival estimates). In general, the estimation of pup and adult survival often show stronger patterns across the survey scenarios, but likely for two different reasons. Pup survival is intentionally simulated to have higher variability to reflect ecological theory and empirical estimates, and therefore may have poorer precision or increased bias. Adult 5+ survival, on the other hand, has minimal simulated variability but will always be informed by fewer branded cohorts, which can be influential in the shorter study time horizon (e.g., adult survival would only be informed by 2 cohorts in a 10-year study with triennial branding). 

#### Coefficient of variation   
The CV values were relatively low, varied for each age class, and followed an expected pattern across survey features, with the most precise estimates arising in scenarios with larger sample sizes, the longer study horizon, and more frequent branding (`r figs('cv_cont_dot', display = 'cite')`). Posterior median CVs were generally low, but smaller for juveniles and adults (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiJ', 'phiA'), 'value']),2)`) and higher for younger age classes (<`r round(max(mean.cv.20[mean.cv.20$variable %in% c('phiP', 'phi1', 'phi2'), 'value']),2)`) across all scenarios. For the 20-year study horizon and medium cohort size, CV values for pup survival decreased by `r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 3, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Medium' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% when moving from triennial to biennial branding and decreased by 
`r round(abs(mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']-mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'High' & mean.cv.20$survey_freq == 2, 'value']/mean.cv.20[mean.cv.20$variable == 'phiP' & mean.cv.20$N == 100 & mean.cv.20$length == 20 & mean.cv.20$detection == 'Low' & mean.cv.20$survey_freq == 2, 'value']),2)*100`% 
when moving from low to high detection rates at biennial branding (i.e., branding frequency has a stronger effect than detection). Cohort sample size and branding frequency have a greater effect on CV values in scenarios with the 10-year study horizon than the 20-year study horizon where precision is generally higher.  

In examining the probability of the CV being below 0.125 (the threshold used in MMPA permit applications for sea lion branding) across all simulations, we can see the importance of a longer study time horizon and branding frequency. The MMPA permit application benchmark can be achieved reliably (>75%) for juveniles and adults in all scenarios and achieved reliably for younger age classes in scenarios with: (1) annual branding and greater than low detection, (2) biennial branding over a longer study with medium-high detection, or (3) triennial branding over a longer study with larger sample sizes, though the probability for pup survival rates in these instances is still lower (50-75%) (`r figs('cv_thresh_dot', display = 'cite')`). In short, sample size and branding frequency can compensate for other "losses" of information to a degree that increasing detection probability (within the range studied here) cannot. Study length, in this case though, provides the greatest improvements:  the probability of achieving a cv<0.125 for pup survival for a cohort size of N = 100 individuals increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 3 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% by moving from triennial to biennial branding in a 10-yr study whereas it increases from `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 10, 'value_cat'], 2)*100`% to `r round(mean.cv.thresh.20[mean.cv.thresh.20$variable == 'phiP' & mean.cv.thresh.20$N == 100 & mean.cv.thresh.20$detection == 'Medium' & mean.cv.thresh.20$survey_freq == 2 & mean.cv.thresh.20$length == 20, 'value_cat'], 2)*100`% when maintaining biennial branding but moving from a 10-yr to a 20-yr study. 

#### Detecting a difference in survival  
The patterns in probability of detecting a difference between the mean survival rates estimated over the study period and a pre-established "baseline" across survey features are similar to those of CV results. Here, however, it is exceedingly important to focus on relative trends, as the reported probabilities are a direct product of the percent difference that is examined - an analytical choice that could easily be modified. As described above, we examined two sets of percent differences: a smaller (15%, 10%, 5%, 2.5% for pups, age-1:2, juveniles, and adults, respectively) and larger (20%, 15%, 10%, 5%) difference between baseline and true data-generating values. Naturally, the probability of detecting a small difference will be lower than that of detecting a large difference, as the inherent uncertainty in survival estimates captured by the posterior distribution would be more likely to overlap with a baseline threshold that is closer to the true data-generating value. We largely report results for scenarios examining data generated with a large difference from a baseline (see Appendix for probabilities of detecting a small difference). 

Overall, the probability of detecting a difference in survival rates varied by age class and across branding frequency, cohort size, and study length (`r figs('cri_dot', display = 'cite')`). In a 10-yr study, the probability of detecting a difference was consistently lowest for adults. The probability of reliably (>75%) detecting a large difference in adult survival in a 10-yr study was only achieved in the best survey circumstance (annual branding of the highest cohort size and detection level) and was generally only reliably achieved for other age classes with annual branding. In contrast, a large difference in adult survival was reliably detected over a 20-yr study horizon in all survey scenarios except triennial branding of the smallest cohort size. However, reliably detecting large differences in pup and yearling survival over the 20-yr study horizon still required either (a) annual branding or (b) biennial branding and larger cohort sizes, and was not reliably achieved in any scenario with triennial branding (`r figs('cri_dot', display = 'cite')`). The probabilities of detecting a smaller difference in survival was overall much lower and could only be reliably achieved for pups in a 10-yr study under the best survey circumstances or with a 20-yr study (Appendix). 

As noted above, we also examined the probability of detecting a difference in survival across a combined "survey effort" metric that combined branding frequency and detection probability. These results highlight the strength of increasing branding frequency in improving estimation relative to increasing detection probability (`r figs('effort_dot', display = 'cite')`). Specifically, in a 20-yr study with a smaller (N = 50) branding cohort size, increasing survey effort by improving branding frequency alone increased the probability of detecting a large difference in survival by `r abs(round(effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value']-effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'High', 'value']/effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value'],2))*100`% (`r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'Low', 'value']*100`% to `r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Branding frequency only' & effort_dat$step == 'High', 'value']*100`%) compared to the `r abs(round(effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value']-effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Detection only' & effort_dat$step == 'High', 'value']/effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value'],2))*100`% increase (`r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Detection only' & effort_dat$step == 'Low', 'value']*100`% to `r effort_dat[effort_dat$N==50 & effort_dat$length == 20 & effort_dat$threshold == 'dec_big' & effort_dat$variable == 'phiP' & effort_dat$category == 'Detection only' & effort_dat$step == 'High', 'value']*100`%) achieved by increasing detection probabilities alone. This pattern was similar across cohort sample sizes, study lengths, and both small and large survival difference thresholds (`r figs('effort_dot', display = 'cite')`). 

#### Relative bias and RMSE
Relative bias did not exhibit strong patterns across age classes and was generally low (<`r round(max(mean.rel.bias.20$value),1)`%) for all survey scenarios (`r figs('bias_dot', display = 'cite')`). Relative bias for pup survival was on average `r round(mean(mean.rel.bias.20[mean.rel.bias.20$length == 10 & mean.rel.bias.20$variable == 'phiP', 'value']),1)`% for all scenarios with a 10-yr study horizon compared to `r round(mean(mean.rel.bias.20[mean.rel.bias.20$length == 20 & mean.rel.bias.20$variable == 'phiP', 'value']),1)`% for 20-yr study designs. Similarly, average relative bias for pup survival was higher for triennial branding scenarios (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Triennial' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) compared to that of biennial (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Biennial' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) and annual (`r round(mean(mean.rel.bias.20[mean.rel.bias.20$survey_freq == 'Annual' & mean.rel.bias.20$variable == 'phiP', 'value']),1)`%) branding.  

Model performance in terms of RMSE followed an expected pattern across survey features and values were generally very low (<`r round(max(mean.rmse.20$value),2)`) across all survey scenarios (`r figs('rmse_dot', display = 'cite')`). Specifically, RMSE values were lower (indicating greater precision and lower bias) for juvenile and adult survival and higher for younger age classes. Values were higher for triennial branding and lower cohort sample sizes for both 10- and 20-year study horizons.  
 
### Discussion  
 
- Aims/results/methods review
-- Review most compelling results
-- Summarize benefits/applications/importance
 
- Review other studies that have done this?
-- Example 1
-- Example 2
 
- What it means for SSL  
-- Study design must also consider "risk tolerance" and management goals

-- What are those for SSL? They vary across space (and time as management needs change?)
 
-- Goals have to be re-evaluated in iterative process

- Recommendations for mark-resight designs generally
-- Example 1
 
- Conclusion
-- Benefits and challenges of study
-- Important for future of dwindling funding

### Figures and tables  

```{r cv continuous dot, fig.height = 6, fig.width = 7}

cv_cont_dot

```
`r figs('cv_cont_dot', caption = 'Mean and 95% quantiles for coefficient of variation (CV) values for age-specific survival rates across survey design features, including branding frequency, branding cohort size, study time horizon, and mark-resight detection probability across all simulations (n = 100).')`


```{r cv threshold dot, fig.height = 6, fig.width = 8}

cv_thresh_dot

```
`r figs('cv_thresh_dot', caption = 'Probability of the coefficient of variation for age-specific survival rates being less than 0.125 across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability.')`


```{r detect change, fig.height = 6, fig.width = 8}

cri_dot_big

```
`r figs('cri_dot_big', caption = 'Probability of detecting a larger difference in age-specific survival rates across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability.')`

```{r effort grid, fig.height = 4, fig.width = 6}

effort_grid

```
`r figs('effort_grid', caption = 'Schematic of the combinations of branding frequency and detection features that comprise the combined survey effort levels of low, medium, and high.')`

```{r effort, fig.height = 6, fig.width = 8}

effort_dot

```
`r figs('effort_dot', caption = 'Probability of detecting smaller and larger differences in pup survival with successive gains in survey effort (combinations of detection probability and branding frequency) across branding cohort size and study time horizon.')`

```{r bias fig, fig.height = 5, fig.width = 7}

bias_dot

```
`r figs('bias_dot', caption = 'Mean relative bias (%) for age-specific survival rates across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across simulations (n = 100).')`



```{r RMSE fig, fig.height = 5, fig.width = 7}

rmse_dot

```
`r figs('rmse_dot', caption = 'Mean root mean square error (RMSE) for age-specific survival rates across survey design features, including branding frequency, study time horizon, branding cohort size, and mark-resight detection probability across simulations (n = 100).')`

### Literature cited



### Appendix  
More sample sizes, more facets. 

```{r CV heatmap all facets, fig.height = 6, fig.width = 8, eval = F}

cv_heat_cont

```
Figure S1. CVs across all sample sizes and survey features.

```{r CV threshold heatmap all facets, fig.height = 6, fig.width = 8, eval = F}

cv_thresh_heat

```
Figure S2. Probability of meeting CV threshold across all sample sizes and survey features.

```{r change more yrs, fig.height = 7, fig.width = 9}

cri_dot_app

```
Figure S3. Probability of detecting change in survival across all sample sizes and survey features. 

```{r change all facets, fig.height = 7, fig.width = 9}

cri_all_cont_heat

```
Figure S4. Probability of detecting change in survival across all sample sizes and survey features. 


```{r bias app, fig.height = 5, fig.width = 7}

bias_heat
# bias_dot

```
Figure S5. Relative bias (%). Heat vs. dot?


```{r RMSE app, fig.height = 5, fig.width = 7}

rmse_heat
# rmse_dot

```
Figure S6. RMSE. Heat vs. dot? 

