---
title: "SSL_FitureProof_sim"
output: word_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, eval = FALSE, message = F, warning = F)

library(here) #v1.0.1
library(dplyr) #v1.0.5
library(nimble) #v0.12.1
library(coda)
library(ggh4x)
library(knitr)
library(readr)
library(logitnorm)

source(here::here('scripts', 'PlotTheme.R'))

eDPS_dat <- readRDS(here::here('results', 'simpleAge', 'out_ME.RDS'))

posts <- eDPS_dat[,c('mu.P', 'mu.1', 'mu.2', 'mu.J', 'mu.A',
                     'int.phiP', 'int.phi1', 'int.phi2', 'int.phiJ', 'int.phiA',
                      'sigmaP', 'sigma1', 'sigma2', 'sigmaJ', 'sigmaA')]
outmat <- as.matrix(posts)

eDPS_ests <- data.frame(
  med = apply(outmat, 2, function(x) quantile(x, probs = 0.5, na.rm = T, names = F)),
  lower = apply(outmat, 2, function(x) quantile(x, probs = 0.025, na.rm = T, names = F)),
  upper = apply(outmat, 2, function(x) quantile(x, probs = 0.975, na.rm = T, names = F)))
eDPS_ests$variable <- row.names(eDPS_ests)



```

```{r functions}

# Define function to simulate multistate capture-recapture data
simul.ms <- function(STATE, OBS, marked, unobservable = NA){
   # Unobservable: number of state that is unobservable
   n.occasions <- dim(STATE)[4] + 1
   CH <- CH.TRUE <- matrix(NA, ncol = n.occasions, nrow = sum(marked))
   # Define a vector with the occasion of marking
   mark.occ <- matrix(0, ncol = dim(STATE)[1], nrow = sum(marked))
   g <- colSums(marked)
   for (s in 1:dim(STATE)[1]){
   # for (s in 1:1){
      if (g[s]==0) next  # individuals only released as pups, state 1, skip others
      mark.occ[(cumsum(g[1:s])-g[s]+1)[s]:cumsum(g[1:s])[s],s] <-
      rep(1:n.occasions, marked[1:n.occasions,s])
      } #s
   #first occasion
   for (i in 1:sum(marked)){
      for (s in 1:dim(STATE)[1]){
         if (mark.occ[i,s]==0) next
         first <- mark.occ[i,s]
         CH[i,first] <- s
         CH.TRUE[i,first] <- s
         } #s
      #subsequent occasions
      for (t in (first+1):n.occasions){
         # Multinomial trials for state transitions
         if (first==n.occasions) next
         state <- which(rmultinom(1, 1, STATE[CH.TRUE[i,t-1],,i,t-1])==1)
         CH.TRUE[i,t] <- state
         # Multinomial trials for observation process
         event <- which(rmultinom(1, 1, OBS[CH.TRUE[i,t],,i,t-1])==1)
         CH[i,t] <- event
         } #t
      } #i
   # Replace the NA and the highest state number (dead) in the file by 0
   CH[is.na(CH)] <- 0
   CH[CH==dim(STATE)[1]] <- 0
   CH[CH==unobservable] <- 0
   id <- numeric(0)
   for (i in 1:dim(CH)[1]){
      z <- min(which(CH[i,]!=0))
      ifelse(z==dim(CH)[2], id <- c(id,i), id <- c(id))
      }
   return(list(CH=CH[-id,], CH.TRUE=CH.TRUE[-id,]))
   # CH: capture histories to be used
   # CH.TRUE: capture histories with perfect observation
   }

# Function to create known latent states z
known.state.ms <- function(ms, notseen){
   # notseen: label for not seen
   state <- ms
   state[state==notseen] <- NA
   for (i in 1:dim(ms)[1]){
      m <- min(which(!is.na(state[i,])))
      state[i,m] <- NA
      }
   return(state)
   }

# Function to create initial values for unknown z
cjs.init <- function(ch, f){
  inits <- ch    #initialize with observations up until states diverge from observations (4yr olds)
  for(i in 1:dim(ch)[1]) {
    # for(i in 1:10) { 
    inits[i,f[i]] <- NA #pups at release
      if(n.occasions-f[i]>=1){   
        inits[i,(f[i] + 1)] <- 2} #1 yr old
      if(n.occasions-f[i]>=2){
        inits[i,(f[i] + 2)] <- 3}  #2 yr old
      if(n.occasions-f[i]>=3){
        inits[i,(f[i] + 3)] <- 4} #3 yr old
    if(n.occasions-f[i]>=4){
        inits[i,(f[i] + 4)] <- 5}
    if(n.occasions-f[i]>=5){
        inits[i,(f[i] + 5)] <- 6}
    if(n.occasions-f[i]>=6){
        inits[i,(f[i] + 6)] <- 7}
    if(n.occasions-f[i]>=7){
        inits[i,(f[i] + 7)] <- 8}
    if(n.occasions-f[i]>=8){
        inits[i,(f[i] + 8)] <- 9}
    if(n.occasions-f[i]>=9){
        inits[i,(f[i] + 9)] <- 10}
      if(n.occasions-f[i]>=10) {
        inits[i,((f[i] + 10):n.occasions)] <- 11} #all 10yrs+ are A
  } #i
  return(inits)
}

#for the model
getPHI <- nimbleFunction(
  run = function(z=double(0), phiP=double(0), phi1=double(0), phi2=double(0), phi3=double(0), phi4=double(0),
                 phi5=double(0), phi6=double(0), phi7=double(0), phi8=double(0), 
                 phi9=double(0), phiA=double(0)) {
   returnType(double(1))
   ans <- rep(0,12)
     if(z==1)   ans <- c(0,phiP,0,0,0,0,0,0,0,0,0,1-phiP)  #pup
     if(z==2)   ans <- c(0,0,phi1,0,0,0,0,0,0,0,0,1-phi1)  #yearling   
     if(z==3)   ans <- c(0,0,0,phi2,0,0,0,0,0,0,0,1-phi2)  #2yr
     if(z==4)   ans <- c(0,0,0,0,phi3,0,0,0,0,0,0,1-phi3)  #3yr 
     if(z==5)   ans <- c(0,0,0,0,0,phi4,0,0,0,0,0,1-phi4)  #4yr
     if(z==6)   ans <- c(0,0,0,0,0,0,phi5,0,0,0,0,1-phi5)  #5yr           
     if(z==7)   ans <- c(0,0,0,0,0,0,0,phi6,0,0,0,1-phi6)  #6yr 
     if(z==8)   ans <- c(0,0,0,0,0,0,0,0,phi7,0,0,1-phi7)       
     if(z==9)   ans <- c(0,0,0,0,0,0,0,0,0,phi8,0,1-phi8)       
     if(z==10)  ans <- c(0,0,0,0,0,0,0,0,0,0,phi9,1-phi9)   
     if(z==11)  ans <- c(0,0,0,0,0,0,0,0,0,0,phiA,1-phiA)       
     if(z==12)  ans <- c(0,0,0,0,0,0,0,0,0,0,0,1) #D

   return(ans)
 }
)

#observations 
getP <- nimbleFunction(
  run = function(z=double(0), p1=double(0), p2=double(0), pJ=double(0), pA=double(0)) {
   returnType(double(1))
   ans <- rep(0,12)
     if(z==1)   ans <- c(1,0,0,0,0,0,0,0,0,0,0,0) #pups seen as pups
     if(z==2)   ans <- c(0,p1,0,0,0,0,0,0,0,0,0,1-p1)   #1yr      
     if(z==3)   ans <- c(0,0,p2,0,0,0,0,0,0,0,0,1-p2)   #2yr
     if(z==4)   ans <- c(0,0,0,pJ,0,0,0,0,0,0,0,1-pJ)   #3yr
     if(z==5)   ans <- c(0,0,0,0,pJ,0,0,0,0,0,0,1-pJ)   #4yr 
     if(z==6)   ans <- c(0,0,0,0,0,pA,0,0,0,0,0,1-pJ)   #5yr           
     if(z==7)   ans <- c(0,0,0,0,0,0,pA,0,0,0,0,1-pJ)   #6yr  
     if(z==8)   ans <- c(0,0,0,0,0,0,0,pA,0,0,0,1-pA)   #7yr  
     if(z==9)   ans <- c(0,0,0,0,0,0,0,0,pA,0,0,1-pA)   #8yr  
     if(z==10)  ans <- c(0,0,0,0,0,0,0,0,0,pA,0,1-pA)   #9yr  
     if(z==11)  ans <- c(0,0,0,0,0,0,0,0,0,0,pA,1-pA)   #pA
     if(z==12)  ans <- c(0,0,0,0,0,0,0,0,0,0,0,1)       #nd

   return(ans)
 }
)


```


```{r scenarios and parameters}

scenario <- 41 #1-45
nsim <- 25

thresh_small <- c(0.15, 0.1, 0.1, 0.05, 0.025)
thresh_big <- c(0.2, 0.15, 0.15, 0.1, 0.05)

#batch 7
batch <- 9 #7
thresh <- thresh_small
v_thresh <- 'small_decrease'

# batch <- 12 #10 #8
# thresh <- thresh_big
# v_thresh <- 'big_decrease'

n.states <- 12
n.obs <- 12
n.occasions <- 11 #10 years of resighting

#define rates
#survival
phi.pars.names <- c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA')

#not sure about how low phiP and phiA are for eDPS
# phi.pars <- c(eDPS_ests['int.phiP', 'med'], eDPS_ests['int.phi1', 'med'], 
#                  eDPS_ests['int.phi2', 'med'], eDPS_ests['int.phiJ', 'med'], eDPS_ests['int.phiA', 'med'])
phi.pars <- c(0.55, 0.7, 0.8, 0.88, 0.92) #generally from wDPS mean

phi.sim <- c(phi.pars[1]-phi.pars[1]*thresh[1],
             phi.pars[2]-phi.pars[2]*thresh[2],
             phi.pars[3]-phi.pars[3]*thresh[3],
             phi.pars[4]-phi.pars[4]*thresh[4],
             phi.pars[5]-phi.pars[5]*thresh[5])

#detection
p.pars.names <- c('p1', 'p2', 'pJ', 'pA')
p.pars <- c(0.6, 0.6, 0.7, 0.8)

#survey features
#number of marked individuals at each release
n.brand.50 <- 50 
n.brand.75 <- 75
n.brand.100 <- 100
n.brand.150 <- 150
n.brand.200 <- 200

pars.1 <- c(p.pars-p.pars*0.2, n.brand.50, rep(n.brand.50, n.occasions))
pars.2 <- c(p.pars-p.pars*0.2, n.brand.75, rep(n.brand.75, n.occasions))
pars.3 <- c(p.pars-p.pars*0.2, n.brand.100, rep(n.brand.100, n.occasions))
pars.4 <- c(p.pars-p.pars*0.2, n.brand.150, rep(n.brand.150, n.occasions))
pars.5 <- c(p.pars-p.pars*0.2, n.brand.200, rep(n.brand.200, n.occasions))

pars.6 <- c(p.pars, n.brand.50, rep(n.brand.50, n.occasions))
pars.7 <- c(p.pars, n.brand.75, rep(n.brand.75, n.occasions))
pars.8 <- c(p.pars, n.brand.100, rep(n.brand.100, n.occasions))
pars.9 <- c(p.pars, n.brand.150, rep(n.brand.150, n.occasions))
pars.10 <- c(p.pars, n.brand.200, rep(n.brand.200, n.occasions))

pars.11 <- c(p.pars+p.pars*0.2, n.brand.50, rep(n.brand.50, n.occasions))
pars.12 <- c(p.pars+p.pars*0.2, n.brand.75, rep(n.brand.75, n.occasions))
pars.13 <- c(p.pars+p.pars*0.2, n.brand.100, rep(n.brand.100, n.occasions))
pars.14 <- c(p.pars+p.pars*0.2, n.brand.150, rep(n.brand.150, n.occasions))
pars.15 <- c(p.pars+p.pars*0.2, n.brand.200, rep(n.brand.200, n.occasions))

#biennial
#adding one marked individual in last occasion to avoid breaking the simulation function - fix later
pars.16 <- c(p.pars-p.pars*0.2, n.brand.50, c(rep(c(n.brand.50,0), (n.occasions/2)-1),n.brand.50,0,1))
pars.17 <- c(p.pars-p.pars*0.2, n.brand.75, c(rep(c(n.brand.75,0), (n.occasions/2)-1),n.brand.75,0,1))
pars.18 <- c(p.pars-p.pars*0.2, n.brand.100, c(rep(c(n.brand.100,0), (n.occasions/2)-1),n.brand.100,0,1))
pars.19 <- c(p.pars-p.pars*0.2, n.brand.150, c(rep(c(n.brand.150,0), (n.occasions/2)-1),n.brand.150,0,1))
pars.20 <- c(p.pars-p.pars*0.2, n.brand.200, c(rep(c(n.brand.200,0), (n.occasions/2)-1),n.brand.200,0,1))

pars.21 <- c(p.pars, n.brand.50, c(rep(c(n.brand.50,0), (n.occasions/2)-1),n.brand.50,0,1))
pars.22 <- c(p.pars, n.brand.75, c(rep(c(n.brand.75,0), (n.occasions/2)-1),n.brand.75,0,1))
pars.23 <- c(p.pars, n.brand.100, c(rep(c(n.brand.100,0), (n.occasions/2)-1),n.brand.100,0,1))
pars.24 <- c(p.pars, n.brand.150, c(rep(c(n.brand.150,0), (n.occasions/2)-1),n.brand.150,0,1))
pars.25 <- c(p.pars, n.brand.200, c(rep(c(n.brand.200,0), (n.occasions/2)-1),n.brand.200,0,1))

pars.26 <- c(p.pars+p.pars*0.2, n.brand.50, c(rep(c(n.brand.50,0), (n.occasions/2)-1),n.brand.50,0,1))
pars.27 <- c(p.pars+p.pars*0.2, n.brand.75, c(rep(c(n.brand.75,0), (n.occasions/2)-1),n.brand.75,0,1))
pars.28 <- c(p.pars+p.pars*0.2, n.brand.100, c(rep(c(n.brand.100,0), (n.occasions/2)-1),n.brand.100,0,1))
pars.29 <- c(p.pars+p.pars*0.2, n.brand.150, c(rep(c(n.brand.150,0), (n.occasions/2)-1),n.brand.150,0,1))
pars.30 <- c(p.pars+p.pars*0.2, n.brand.200, c(rep(c(n.brand.200,0), (n.occasions/2)-1),n.brand.200,0,1))

#triennial
pars.31 <- c(p.pars-p.pars*0.2, n.brand.50, c(rep(c(n.brand.50,0,0), (n.occasions/3)),n.brand.50,1))
pars.32 <- c(p.pars-p.pars*0.2, n.brand.75, c(rep(c(n.brand.75,0,0), (n.occasions/3)),n.brand.75,1))
pars.33 <- c(p.pars-p.pars*0.2, n.brand.100, c(rep(c(n.brand.100,0,0), (n.occasions/3)),n.brand.100,1))
pars.34 <- c(p.pars-p.pars*0.2, n.brand.150, c(rep(c(n.brand.150,0,0), (n.occasions/3)),n.brand.150,1))
pars.35 <- c(p.pars-p.pars*0.2, n.brand.200, c(rep(c(n.brand.200,0,0), (n.occasions/3)),n.brand.200,1))

pars.36 <- c(p.pars, n.brand.50, c(rep(c(n.brand.50,0,0), (n.occasions/3)),n.brand.50,1))
pars.37 <- c(p.pars, n.brand.75, c(rep(c(n.brand.75,0,0), (n.occasions/3)),n.brand.75,1))
pars.38 <- c(p.pars, n.brand.100, c(rep(c(n.brand.100,0,0), (n.occasions/3)),n.brand.100,1))
pars.39 <- c(p.pars, n.brand.150, c(rep(c(n.brand.150,0,0), (n.occasions/3)),n.brand.150,1))
pars.40 <- c(p.pars, n.brand.200, c(rep(c(n.brand.200,0,0), (n.occasions/3)),n.brand.200,1))

pars.41 <- c(p.pars+p.pars*0.2, n.brand.50, c(rep(c(n.brand.50,0,0), (n.occasions/3)),n.brand.50,1))
pars.42 <- c(p.pars+p.pars*0.2, n.brand.75, c(rep(c(n.brand.75,0,0), (n.occasions/3)),n.brand.75,1))
pars.43 <- c(p.pars+p.pars*0.2, n.brand.100, c(rep(c(n.brand.100,0,0), (n.occasions/3)),n.brand.100,1))
pars.44 <- c(p.pars+p.pars*0.2, n.brand.150, c(rep(c(n.brand.150,0,0), (n.occasions/3)),n.brand.150,1))
pars.45 <- c(p.pars+p.pars*0.2, n.brand.200, c(rep(c(n.brand.200,0,0), (n.occasions/3)),n.brand.200,1))


#marked matrix
marked <- matrix(0, ncol = n.states, nrow = n.occasions)
marked[,1] <- eval(parse(text = paste0('pars.', scenario)))[6:(n.occasions+5)] 

#storage
n_params <- length(c(phi.pars, p.pars))
out_median <- matrix(NA, nsim, n_params+2) #rhat storage
out_true <- matrix(NA, nsim, n_params) 
bias <- rmse <- matrix(NA, nsim, n_params) 

cv <- dec_little5 <- dec_little10 <- inc_little5 <- inc_little10 <- matrix(NA, nsim, length(phi.pars)) 

pars <- eval(parse(text = paste0('pars.', scenario)))


```


```{r simulate and run}

for (s in 1:nsim) {
  
# phi.pars.t <- data.frame(phiP = rlogitnorm(n.occasions-1, eDPS_ests['mu.P', 'med'], 
#                                            eDPS_ests['sigmaP', 'med']),
#                          phi1 = rlogitnorm(n.occasions-1, eDPS_ests['mu.1', 'med'], 
#                                            eDPS_ests['sigma1', 'med']),
#                          phi2 = rlogitnorm(n.occasions-1, eDPS_ests['mu.2', 'med'], 
#                                            eDPS_ests['sigma2', 'med']),
#                          phiJ = rlogitnorm(n.occasions-1, eDPS_ests['mu.J', 'med'], 
#                                            eDPS_ests['sigmaJ', 'med']),
#                          phiA = rlogitnorm(n.occasions-1, eDPS_ests['mu.A', 'med'], 
#                                            eDPS_ests['sigmaA', 'med']))

#decreasing scenarios
phi.pars.t <- data.frame(phiP = rlogitnorm(n.occasions-1, qlogis(phi.pars[1]-(phi.pars[1]*thresh[1])), 
                                           eDPS_ests['sigmaP', 'med']),
                         phi1 = rlogitnorm(n.occasions-1, qlogis(phi.pars[2]-(phi.pars[2]*thresh[2])), 
                                           eDPS_ests['sigma1', 'med']),
                         phi2 = rlogitnorm(n.occasions-1, qlogis(phi.pars[3]-(phi.pars[3]*thresh[3])), 
                                           eDPS_ests['sigma2', 'med']),
                         phiJ = rlogitnorm(n.occasions-1, qlogis(phi.pars[4]-(phi.pars[4]*thresh[4])), 
                                           eDPS_ests['sigmaJ', 'med']),
                         phiA = rlogitnorm(n.occasions-1, qlogis(phi.pars[5]-(phi.pars[5]*thresh[5])), 
                                           eDPS_ests['sigmaA', 'med']))

#increasing scenarios
# phi.pars.t <- data.frame(phiP = rlogitnorm(n.occasions-1, qlogis(phi.pars[1]+(phi.pars[1]*thresh[1])), 
#                                            eDPS_ests['sigmaP', 'med']),
#                          phi1 = rlogitnorm(n.occasions-1, qlogis(phi.pars[2]+(phi.pars[2]*thresh[2])), 
#                                            eDPS_ests['sigma1', 'med']),
#                          phi2 = rlogitnorm(n.occasions-1, qlogis(phi.pars[3]+(phi.pars[3]*thresh[3])), 
#                                            eDPS_ests['sigma2', 'med']),
#                          phiJ = rlogitnorm(n.occasions-1, qlogis(phi.pars[4]+(phi.pars[4]*thresh[4])), 
#                                            eDPS_ests['sigmaJ', 'med']),
#                          phiA = rlogitnorm(n.occasions-1, qlogis(phi.pars[5]+(phi.pars[5]*thresh[5])), 
#                                            eDPS_ests['sigmaA', 'med']))

# 1. State process matrix
totrel <- sum(marked)*(n.occasions-1)
STATE <- array(NA, dim=c(n.states, n.states, totrel, n.occasions-1))
for (i in 1:totrel){
   for (t in 1:(n.occasions-1)){
      STATE[,,i,t] <- matrix(c(
      0,phi.pars.t[t,1],0,0,0,0,0,0,0,0,0,1-phi.pars.t[t,1], #pup
      0,0,phi.pars.t[t,2],0,0,0,0,0,0,0,0,1-phi.pars.t[t,2], #1
      0,0,0,phi.pars.t[t,3],0,0,0,0,0,0,0,1-phi.pars.t[t,3], #2
      0,0,0,0,phi.pars.t[t,4],0,0,0,0,0,0,1-phi.pars.t[t,4], #3
      0,0,0,0,0,phi.pars.t[t,4],0,0,0,0,0,1-phi.pars.t[t,4], #4
      0,0,0,0,0,0,phi.pars.t[t,5],0,0,0,0,1-phi.pars.t[t,5], #5
      0,0,0,0,0,0,0,phi.pars.t[t,5],0,0,0,1-phi.pars.t[t,5], #6
      0,0,0,0,0,0,0,0,phi.pars.t[t,5],0,0,1-phi.pars.t[t,5], #7
      0,0,0,0,0,0,0,0,0,phi.pars.t[t,5],0,1-phi.pars.t[t,5], #8
      0,0,0,0,0,0,0,0,0,0,phi.pars.t[t,5],1-phi.pars.t[t,5], #9
      0,0,0,0,0,0,0,0,0,0,phi.pars.t[t,5],1-phi.pars.t[t,5], #plus
      0,0,0,0,0,0,0,0,0,0,0,1), nrow = n.states, byrow = TRUE)
      } #t
   } #i

# 2.Observation process matrix
OBS <- array(NA, dim=c(n.states, n.obs, totrel, n.occasions-1))
for (i in 1:totrel){
   for (t in 1:(n.occasions-1)){
      OBS[,,i,t] <- matrix(c(
     1,0,0,0,0,0,0,0,0,0,0,0,
     0,pars[1],0,0,0,0,0,0,0,0,0,1-pars[1],   #1yr      
     0,0,pars[2],0,0,0,0,0,0,0,0,1-pars[2],   #2yr
     0,0,0,pars[3],0,0,0,0,0,0,0,1-pars[3],   #3yr
     0,0,0,0,pars[3],0,0,0,0,0,0,1-pars[3],   #4yr 
     0,0,0,0,0,pars[4],0,0,0,0,0,1-pars[4],   #5yr           
     0,0,0,0,0,0,pars[4],0,0,0,0,1-pars[4],   #6yr  
     0,0,0,0,0,0,0,pars[4],0,0,0,1-pars[4],   #7yr  
     0,0,0,0,0,0,0,0,pars[4],0,0,1-pars[4],   #8yr  
     0,0,0,0,0,0,0,0,0,pars[4],0,1-pars[4],   #9yr  
     0,0,0,0,0,0,0,0,0,0,pars[4],1-pars[4],   #pA
     0,0,0,0,0,0,0,0,0,0,0,1), nrow = n.states, byrow = TRUE)
      } #t
   } #i

# Execute simulation function
sim <- simul.ms(STATE, OBS, marked)
CH <- sim$CH
CH.TRUE <- sim$CH.TRUE

# Compute vector with occasion of first capture
get.first <- function(x) min(which(x!=0))
f <- apply(CH, 1, get.first)

# Recode CH matrix: note, a 0 is not allowed; 12 = not seen
rCH <- CH          # Recoded CH
rCH[rCH==0] <- 12

z.init <- as.matrix(cjs.init(rCH, f))
# z.st <- known.state.ms(rCH, 12)

#model text
SSL_CJS <- nimbleCode({

# Priors and constraints
  for (i in 1:n_ind) { 
    for (t in 1:(n.occasions - 1)) {
      logit(phiP[i,t]) <- mu.P + epsP[t]
      logit(p1[i,t]) <- mu.p1 
    } #t 
    
    for (t in 2:(n.occasions-1)) {
      logit(phi1[i,t]) <- mu.1 + eps1[t]
      logit(p2[i,t]) <- mu.p2  
    }
    
    for (t in 3:(n.occasions-1)) {
      logit(phi2[i,t]) <- mu.2 + eps2[t]
      logit(pJ[i,t]) <- mu.pJ 
    }
    
    for (t in 4:(n.occasions-1)) { 
      logit(phi3[i,t]) <- mu.J + epsJ[t]
    } #t psi
    
    for (t in 5:(n.occasions-1)) {
      logit(phi4[i,t]) <- mu.J + epsJ[t]
      logit(pA[i,t]) <- mu.pA 
    } #t 
    
    for (t in 6:(n.occasions-1)) {  
      logit(phi5[i,t]) <- mu.A + epsA[t]
    } #t 
    
    for (t in 7:(n.occasions-1)) {  
      logit(phi6[i,t]) <- mu.A + epsA[t]
    } #t 
    
    for (t in 8:(n.occasions-1)) {  
      logit(phi7[i,t]) <- mu.A + epsA[t]
    } #t 
    
    for (t in 9:(n.occasions-1)) {  
      logit(phi8[i,t]) <- mu.A + epsA[t]
    } #t 
    
    for (t in 10:(n.occasions-1)) {  
      logit(phi9[i,t]) <- mu.A + epsA[t]
      logit(phiA[i,t]) <- mu.A + epsA[t]
    } #t 
    
    # for (t in 11:(n.occasions-1)) {  
    #   logit(phiA[i,t]) <- mu.A + epsA[t]
    # } #t 
    
  } #ind

    
### Priors
  
   for (t in 1:(n.occasions - 1)) {
      epsP[t] ~ dnorm(0, sd = sigmaP)
    } #t 
    
    for (t in 2:(n.occasions-1)) {
      eps1[t] ~ dnorm(0, sd = sigma1)
    }
    
    for (t in 3:(n.occasions-1)) {
      eps2[t] ~ dnorm(0, sd = sigma2)
    }
    
    for (t in 4:(n.occasions-1)) { 
      epsJ[t] ~ dnorm(0, sd = sigmaJ)
    } #t 
  
    for (t in 6:(n.occasions-1)) {  
      epsA[t] ~ dnorm(0, sd = sigmaA)
    } #t 
  
    sigmaP ~ dexp(1)
    sigma1 ~ dexp(1)
    sigma2 ~ dexp(1)
    sigmaJ ~ dexp(1)
    sigmaA ~ dexp(1)
  
    #p
    mu.p1 <- log(int.p1/(1 - int.p1))
    mu.p2 <- log(int.p2/(1 - int.p2))
    mu.pJ <- log(int.pJ/(1 - int.pJ))
    mu.pA <- log(int.pA/(1 - int.pA))

    int.p1 ~ dunif(0,1)
    int.p2 ~ dunif(0,1)
    int.pJ ~ dunif(0,1)
    int.pA ~ dunif(0,1)

    mu.P <- log(int.phiP/(1 - int.phiP))
    mu.1 <- log(int.phi1/(1 - int.phi1))
    mu.2 <- log(int.phi2/(1 - int.phi2))
    mu.J <- log(int.phiJ/(1 - int.phiJ))
    mu.A <- log(int.phiA/(1 - int.phiA))
    
    int.phiP ~ dunif(0,1)
    int.phi1 ~ dunif(0,1)
    int.phi2 ~ dunif(0,1)
    int.phiJ ~ dunif(0,1)
    int.phiA ~ dunif(0,1)
    
    #for calculating cv
    mean.phiP <- mean(phiP[1:n_ind,1:(n.occasions-1)])
    mean.phi1 <- mean(phi1[1:n_ind,2:(n.occasions-1)])
    mean.phi2 <- mean(phi2[1:n_ind,3:(n.occasions-1)])
    mean.phi3 <- mean(phi3[1:n_ind,4:(n.occasions-1)])
    mean.phi4 <- mean(phi4[1:n_ind,5:(n.occasions-1)])
    mean.phi5 <- mean(phi5[1:n_ind,6:(n.occasions-1)])
    mean.phi6 <- mean(phi6[1:n_ind,7:(n.occasions-1)])
    mean.phi7 <- mean(phi7[1:n_ind,8:(n.occasions-1)])
    mean.phi8 <- mean(phi8[1:n_ind,9:(n.occasions-1)])
    mean.phi9 <- mean(phi9[1:n_ind,10:(n.occasions-1)])
    mean.phiA.temp <- mean(phiA[1:n_ind,10:(n.occasions-1)])

    # mean.phiJ <- mean(c(mean.phi3, mean.phi4))
    # mean.phiA <- mean(c(mean.phi5, mean.phi6, mean.phi7, 
                    # mean.phi8, mean.phi9, mean.phiA.temp))

    mean.phiJ <- mean(c(phi3[1:n_ind,4:(n.occasions-1)], 
                        phi4[1:n_ind,5:(n.occasions-1)]))
    mean.phiA <- mean(c(phi5[1:n_ind,6:(n.occasions-1)], 
                        phi6[1:n_ind,7:(n.occasions-1)], 
                        phi7[1:n_ind,8:(n.occasions-1)], 
                        phi8[1:n_ind,9:(n.occasions-1)], 
                        phi9[1:n_ind,10:(n.occasions-1)], 
                        phiA[1:n_ind,10:(n.occasions-1)]))

    #mean phi at 5 yrs
    mean.phiP.5 <- mean(phiP[1:n_ind,1:(n.occasions-5)])
    mean.phi1.5 <- mean(phi1[1:n_ind,2:(n.occasions-5)])
    mean.phi2.5 <- mean(phi2[1:n_ind,3:(n.occasions-5)])

    mean.phiJ.5 <- mean(c(phi3[1:n_ind,4:(n.occasions-5)], 
                        phi4[1:n_ind,5:(n.occasions-5)]))
    mean.phiA.5 <- mean(c(phi5[1:n_ind,6:(n.occasions-5)]))
    

    #likelihood
for (i in 1:n_ind) { #females
    z[i, f[i]:f[i]] <- 1 #pups at first capture

for (t in (f[i] + 1):n.occasions) {
      z[i,t] ~ dcat(state_probs[i,t-1,1:12])
      y[i,t] ~ dcat(event_probs[i,t,1:12])
      
    state_probs[i,t-1,1:12] <- getPHI(z = z[i,t-1], 
                                      phiP = phiP[i,t-1], phi1 = phi1[i,t-1], phi2 = phi2[i,t-1], 
                                      phi3 = phi3[i,t-1], phi4 = phi4[i,t-1], phi5 = phi5[i,t-1], 
                                      phi6 = phi6[i,t-1], phi7 = phi7[i,t-1], phi8 = phi8[i,t-1],
                                      phi9 = phi9[i,t-1], phiA = phiA[i,t-1])
    
    event_probs[i,t,1:12] <- getP(z = z[i,t], 
                                    p1 = p1[i,t-1], p2 = p2[i,t-1], pJ = pJ[i,t-1], pA = pA[i,t-1])
    } #t likelihood 
} #i likelihood 
    
}) # mod   


nim.data <- list(y = rCH)

nim.constants <- list(n_ind = dim(rCH)[1], n.occasions = n.occasions,
                      # mass = mass, site = rook, sex = sex,
                      f = f)

inits <- list(z = z.init)

# ### parameters
params <- c('int.phiP', 'int.phi1', 'int.phi2', 'int.phiJ', 'int.phiA',
            'int.p1', 'int.p2', 'int.pJ', 'int.pA',
            'sigmaP', 'sigma1', 'sigma2', 'sigmaJ', 'sigmaA',
            'mu.P', 'mu.1', 'mu.2', 'mu.J', 'mu.A',
            # 'sd.phiP', 'sd.phi1', 'sd.phi2', 'sd.phiJ', 'sd.phiA',
            'mean.phiP', 'mean.phi1', 'mean.phi2', 'mean.phiJ', 'mean.phiA',
            'mean.phiP.5', 'mean.phi1.5', 'mean.phi2.5', 'mean.phiJ.5', 'mean.phiA.5')

# params <- c('int.phiP', 'int.phi1', 'int.phi2', 'int.phiJ', 'int.phiA',
#             'int.p1', 'int.p2', 'int.pJ', 'int.pA',
#             'sigmaP', 'sigma1', 'sigma2', 'sigmaJ', 'sigmaA',
#             'mu.P', 'mu.1', 'mu.2', 'mu.J', 'mu.A')

### run model
n.iter = 3500; n.chains = 3; n.burnin = 2000; nthin = 3; nAdapt = 20
n.iter = 20000; n.chains = 3; n.burnin = 10000; nthin = 3; nAdapt = 20
# n.iter = 300; n.chains = 3; n.burnin = 20; nthin = 3; nAdapt = 20

Rmodel <- nimbleModel(code = SSL_CJS, 
                      constants = nim.constants, data = nim.data, 
                      calculate = F, check = F, inits = inits)

conf <- configureMCMC(Rmodel, monitors = params, control = list(adaptInterval = nAdapt), 
                      thin = nthin, useConjugacy = FALSE)

Rmcmc <- buildMCMC(conf)  #produce uncompiled R mcmc function
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)

out <- runMCMC(Cmcmc, niter = n.iter, nburnin = n.burnin, nchains = n.chains, inits = inits,
               setSeed = FALSE, progressBar = TRUE, samplesAsCodaMCMC = TRUE)

out_mat <- as.matrix(out)

#summarize output
rhats <- gelman.diag(out[,c(params[1:9])], multivariate=F, autoburnin=F)

rhats_df <- data.frame(rhats = rhats$psrf[,1], names = row.names(rhats$psrf))

out_median[s,] <- c(summary(out[,c(params[1:9])])$q[,"50%"], max(rhats$psrf[,1], na.rm = T),
                    rhats_df[which.max(rhats_df[,1]),2])
colnames(out_median) <- c(names(summary(out[,c(params[1:9])])$q[,"50%"]), 'max_rhat', 'max_rhat_par')

#true values
out_true[s,] <- c(phi.sim, eval(parse(text = paste0('pars.', scenario)))[1:4])
colnames(out_true) <- c(phi.pars.names, p.pars.names)

#bias
bias[s,] <- c((summary(out[,"int.phiP"])$q["50%"]-out_true[s,1])/out_true[s,1],
              (summary(out[,"int.phi1"])$q["50%"]-out_true[s,2])/out_true[s,2],
              (summary(out[,"int.phi2"])$q["50%"]-out_true[s,3])/out_true[s,3],
              (summary(out[,"int.phiJ"])$q["50%"]-out_true[s,4])/out_true[s,4],
              (summary(out[,"int.phiA"])$q["50%"]-out_true[s,5])/out_true[s,5],
              (summary(out[,"int.p1"])$q["50%"]-out_true[s,6])/out_true[s,6],
              (summary(out[,"int.p2"])$q["50%"]-out_true[s,7])/out_true[s,7],
              (summary(out[,"int.pJ"])$q["50%"]-out_true[s,8])/out_true[s,8],
              (summary(out[,"int.pA"])$q["50%"]-out_true[s,9])/out_true[s,9])
colnames(bias) <- c(phi.pars.names, p.pars.names)

#CV
cv[s,] <- c(sd(out_mat[,'mean.phiP'])/summary(out[,"mean.phiP"])$q["50%"],
            sd(out_mat[,'mean.phi1'])/summary(out[,"mean.phi1"])$q["50%"],
            sd(out_mat[,'mean.phi2'])/summary(out[,"mean.phi2"])$q["50%"],
            sd(out_mat[,'mean.phiJ'])/summary(out[,"mean.phiJ"])$q["50%"],
            sd(out_mat[,'mean.phiA'])/summary(out[,"mean.phiA"])$q["50%"])
colnames(cv) <- phi.pars.names

#rmse: sqrt(mean(theta.iter-T)^2)
rmse[s,] <- c(sqrt(mean((out_mat[,'int.phiP']-out_true[s,1])^2)),
              sqrt(mean((out_mat[,'int.phi1']-out_true[s,2])^2)),
              sqrt(mean((out_mat[,'int.phi2']-out_true[s,3])^2)),
              sqrt(mean((out_mat[,'int.phiJ']-out_true[s,4])^2)),
              sqrt(mean((out_mat[,'int.phiA']-out_true[s,5])^2)),
              sqrt(mean((out_mat[,'int.p1']-out_true[s,6])^2)),
              sqrt(mean((out_mat[,'int.p2']-out_true[s,7])^2)),
              sqrt(mean((out_mat[,'int.pJ']-out_true[s,8])^2)),
              sqrt(mean((out_mat[,'int.pA']-out_true[s,9])^2)))
colnames(rmse) <- c(phi.pars.names, p.pars.names)

#detecting departure from baseline phi
cri_pars <- c('int.phiP', 'int.phi1', 'int.phi2', 'int.phiJ', 'int.phiA')

#batch 7 & 8
dec_little5[s,] <- phi.pars >= 
        c(quantile(out_mat[,'mean.phiP.5'], probs = 0.95), 
          quantile(out_mat[,'mean.phi1.5'], probs = 0.95),
          quantile(out_mat[,'mean.phi2.5'], probs = 0.95),
          quantile(out_mat[,'mean.phiJ.5'], probs = 0.95),
          quantile(out_mat[,'mean.phiA.5'], probs = 0.95))
colnames(dec_little5) <- phi.pars.names

dec_little10[s,] <- phi.pars >= 
        c(quantile(out_mat[,'mean.phiP'], probs = 0.95), 
          quantile(out_mat[,'mean.phi1'], probs = 0.95),
          quantile(out_mat[,'mean.phi2'], probs = 0.95),
          quantile(out_mat[,'mean.phiJ'], probs = 0.95),
          quantile(out_mat[,'mean.phiA'], probs = 0.95))
colnames(dec_little10) <- phi.pars.names


cv[s,] <- c(sd(out_mat[,'mean.phiP'])/summary(out[,"mean.phiP"])$q["50%"],
            sd(out_mat[,'mean.phi1'])/summary(out[,"mean.phi1"])$q["50%"],
            sd(out_mat[,'mean.phi2'])/summary(out[,"mean.phi2"])$q["50%"],
            sd(out_mat[,'mean.phiJ'])/summary(out[,"mean.phiJ"])$q["50%"],
            sd(out_mat[,'mean.phiA'])/summary(out[,"mean.phiA"])$q["50%"])
colnames(cv) <- phi.pars.names


} #simulations

# save output
saveRDS(bias, file = here::here('results', 'simpleAge', 'sims',
                                paste('S.', scenario, '_bias', batch, '.rds', sep = '')))
saveRDS(out_median, file = here::here('results', 'simpleAge', 'sims', 
                                      paste('S.', scenario,  '_median', batch, '.rds', sep = '')))
saveRDS(cv, file = here::here('results', 'simpleAge', 'sims', 
                                      paste('S.', scenario,  '_cv', batch, '.rds', sep = '')))
saveRDS(rmse, file = here::here('results', 'simpleAge', 'sims',  
                                      paste('S.', scenario,  '_rmse', batch, '.rds', sep = '')))

#batch 7, 9, 11
saveRDS(dec_little10, file = here::here('results', 'simpleAge', 'sims',
                                      paste('S.', scenario,  '_dec_little10_', batch, '.rds', sep = '')))
saveRDS(dec_little5, file = here::here('results', 'simpleAge', 'sims',
                                      paste('S.', scenario,  '_dec_little5_', batch, '.rds', sep = '')))

#batch 8, 10, 12
#these are the same, just different true values, so used same calculation
# dec_big5 <- dec_little5
# dec_big10 <- dec_little10
# 
# saveRDS(dec_big10, file = here::here('results', 'simpleAge', 'sims',
#                                       paste('S.', scenario,  '_dec_big10_', batch, '.rds', sep = '')))
# saveRDS(dec_big5, file = here::here('results', 'simpleAge', 'sims',
#                                       paste('S.', scenario,  '_dec_big5_', batch, '.rds', sep = '')))


saveRDS(out, file = here::here('results', 'simpleAge', 'sims',
                               paste('S.', scenario, '_chains', batch, '.rds', sep = '')))



```


```{r convergence summary}

library(stringr)
sc <- c(1:45)

scenarios <- data.frame(scenario = c(sc),
                        survey_freq = c(rep(1,15), rep(2,15), rep(3,15)),
                        detection = c(rep(c('Low', 'Low', 'Low', 'Low', 'Low',
                                            'Med', 'Med', 'Med', 'Med', 'Med', 
                                            'High', 'High', 'High', 'High', 'High'), 3)),
                        N = c(rep(c(50,75,100,150,200), 9)))
                        
med.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'median', all.files = FALSE, full.names = F)


converged <- data.frame()
for (f in 1:length(med.files)) {

rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge','sims', 
                                                     med.files[f]))[,'max_rhat']) %>%
  transform(scenario = parse_number(gsub('S.', '', med.files[f]))) %>%
  transform(batch = str_sub(med.files[f], -6,-5)) %>%
  transform(rhat = as.numeric(rhat))

converged <- rbind(converged, rhats)

}

tot_runs <- converged %>%
  filter(!is.na(rhat)) %>%
  group_by(scenario, batch) %>%
  dplyr::summarize(tot = n())

prop_conv <- converged %>%
  filter(rhat<1.10) %>%
  group_by(scenario) %>%
  dplyr::summarize(conv = n()) %>%
  merge(tot_runs, by = 'scenario', all = T) %>%
  transform(prop_conv = round(conv/tot,2)) %>%
  dplyr::select(scenario, tot, prop_conv)

scenarios_tab <- scenarios %>%
  merge(prop_conv, by = 'scenario') %>%
  transform(survey_freq = factor(survey_freq, levels = c(1,2,3),
                                 labels = c('Annual', 'Biennial', 'Triennial')))

kable(scenarios_tab)


```

```{r results bias}

bias.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'bias', all.files = FALSE, full.names = F)

rel.bias <- data.frame()
for (f in 1:length(bias.files)) {
temp.bias <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  bias.files[f])))
#use gsub on bias files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('bias', 'median', bias.files[f])))[,'max_rhat'])

temp.bias$rhat <- as.numeric(rhats$rhat)
temp <- temp.bias %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', bias.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rel.bias <- rbind(rel.bias, temp)

} #rds file

rel.bias <- rel.bias %>%
  filter(rhat < 1.1) 

mean.rel.bias <- data.frame(rel.bias) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value)*100, .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Survey frequency', samp_size = 'Sample size')

phi_pars <- c('phi[P]','phi[1]', 'phi[2]', 'phi[J]', 'phi[A]')
p_pars <- c('p[1]', 'p[2]', 'p[J]', 'p[A]') 
freq_labels <- c('1' = 'Annual', '2' = 'Biennial', '3' = 'Triennial')

#phi
plot_dat <- mean.rel.bias %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
  scale_fill_gradient2(name = "Relative bias (%)",
                      mid = "#FFFFFF", low = "deepskyblue1", high = "red2", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#p
plot_dat <- mean.rel.bias %>% filter(variable %in% c('p1', 'p2', 'pJ', 'pA')) %>%
  transform(variable = factor(variable, 
                              levels = c('p1', 'p2', 'pJ', 'pA'), 
                              labels = p_pars))

ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
  scale_fill_gradient2(name = "Relative bias (%)",
                      mid = "#FFFFFF", low = "deepskyblue1", high = "red2", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


```

```{r results rmse}

rmse.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'rmse', all.files = FALSE, full.names = F)

rmse <- data.frame()
for (f in 1:length(rmse.files)) {
temp.rmse <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  rmse.files[f])))
#use gsub on rmse files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('rmse', 'median', rmse.files[f])))[,'max_rhat'])

temp.rmse$rhat <- as.numeric(rhats$rhat)
temp <- temp.rmse %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', rmse.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

rmse <- rbind(rmse, temp)

} #rds file

rmse <- rmse %>%
  filter(rhat < 1.1) 

mean.rmse <- data.frame(rmse) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Survey frequency', samp_size = 'Sample size')


#phi
plot_dat <- mean.rmse %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "RMSE",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

#p
plot_dat <- mean.rmse %>% filter(variable %in% c('p1', 'p2', 'pJ', 'pA')) %>%
  transform(variable = factor(variable, 
                              levels = c('p1', 'p2', 'pJ', 'pA'), 
                              labels = p_pars))

ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "RMSE",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))

```

```{r results cv}

cv.files3 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv3', all.files = FALSE, full.names = F)

cv.files4 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv4', all.files = FALSE, full.names = F)

cv.files5 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv5', all.files = FALSE, full.names = F)

cv.files6 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv6', all.files = FALSE, full.names = F)

cv.files7 <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = 'cv7', all.files = FALSE, full.names = F)

cv.files <- c(cv.files4, cv.files5, cv.files6, cv.files7)

cv <- data.frame()
for (f in 1:length(cv.files)) {
temp.cv <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cv.files[f])))
#use gsub on cv files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims', 
                                                     gsub('cv', 'median', cv.files[f])))[,'max_rhat'])

temp.cv$rhat <- as.numeric(rhats$rhat)
temp <- temp.cv %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cv.files[f]))) %>%
  transform(value = ifelse(is.nan(value), 0, value))

cv <- rbind(cv, temp)

} #rds file

cv <- cv %>%
  filter(rhat < 1.1) 

mean.cv <- data.frame(cv) %>%
  group_by(variable, scenario) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(variable, detection, N, survey_freq) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Survey frequency', samp_size = 'Sample size')


#phi
plot_dat <- mean.cv %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars))

ggplot(plot_dat, aes(x = factor(detection), y = variable, fill = value)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
 scale_fill_gradient2(name = "cv",
                      mid = "#FFFFFF", low = "#012345", high = "#012345", midpoint = 0) +
  theme_bw() +
  theme(legend.position = 'right',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF"),
        legend.text = element_text(size = 8, vjust = 0.5),
        legend.title = element_text(vjust = 0.8, size = 10)) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


```

```{r results threshold}

library(stringr)

cri.scenarios <- c('dec_little', 'dec_big', 'inc_little', 'inc_big')
cri.scenarios <- c('dec_little', 'dec_big')
append <- c(5,10)

cri.all <- data.frame()

for (a in 1:length(append)) { #files for period length

for (j in 1:length(cri.scenarios)) {
  
cri.files <- list.files(path = here::here('results', 'simpleAge', 'sims'), 
                    pattern = paste0(cri.scenarios[j],append[a]), all.files = FALSE, full.names = F)

cri <- data.frame()
for (f in 1:length(cri.files)) {
temp.cri <- data.frame(readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                  cri.files[f])))
#use gsub on cri files rather than use different list to make sure they match
rhats <- data.frame(rhat = readRDS(file = here::here('results', 'simpleAge', 'sims',
                                                     gsub('median_', 'median', gsub(paste0(cri.scenarios[j], append[a]), 'median', cri.files[f]))))[,'max_rhat'])

temp.cri$rhat <- as.numeric(rhats$rhat)
temp <- temp.cri %>% 
  reshape2::melt(id.vars = 'rhat') %>%
  transform(scenario = parse_number(gsub('S.', '', cri.files[f]))) %>%
  transform(run = str_sub(cri.files[f], -5,-5)) %>%
  transform(length = append[a]) %>%
  # transform(length = ifelse(grepl('little5', cri.files[f]) | grepl('big5', cri.files[f]), 5, 10)) %>%
  transform(threshold = cri.scenarios[j])

cri <- rbind(cri, temp)

} #appending length of year period

cri.all <- rbind(cri, cri.all)

} #rds file
} #j

mean.cri <- data.frame(cri.all) %>%
    merge(scenarios, by = 'scenario', all = F) %>%
  #cri only correct for runs 5 and greater
  # filter(run > 6) %>%
  group_by(threshold, variable, detection, N, survey_freq, length) %>%
  dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA',
                            'p1', 'p2', 'pJ', 'pA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Survey frequency', samp_size = 'Sample size')


plot_dat <- mean.cri %>% filter(grepl('phi', variable)) %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'), 
                              labels = phi_pars)) %>%
  transform(value_cat = ifelse(value < 0.5, "<0.5",
                               ifelse(value >=0.5 & value < 0.8, '0.5-0.8', '>0.8'))) %>%
  transform(value_cat = factor(value_cat, levels = c('<0.5', '0.5-0.8', '>0.8'))) %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big', 'inc_little', 'inc_big'),
                               labels = c('Small decrease', 'Big decrease', 'Small increase', 'Big increase')))


#continuous color scale
#decrease in survival with 5 and 10 yrs of data
ggplot(plot_dat %>% filter(threshold %in% c('Big decrease')), 
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) 

#decrease in survival with 10 yrs of data
ggplot(plot_dat %>% filter(threshold %in% c('Small decrease', 'Big decrease') & length == 10), 
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + threshold, drop = T, 
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) 

#more facets?
ggplot(plot_dat,
       aes(x = factor(detection), y = variable, fill = value)) +
        # aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N + length ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
scale_fill_gradient2(name = "Probability of detecting change",
                  mid = "#FFFFFF", high = "deepskyblue1", low = "red2", midpoint = 0.8) +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable))))))


#categorical colors
ggplot(plot_dat %>% filter(threshold %in% c('Small decrease', 'Big decrease') & length == 10),
       # aes(x = factor(detection), y = variable, fill = value)) +
        aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + threshold, drop = T,
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting change in survival",
                    values = c('firebrick3', 'orange', 'steelblue2'))

ggplot(plot_dat %>% filter(threshold %in% c('Big decrease')),
       # aes(x = factor(detection), y = variable, fill = value)) +
        aes(x = factor(detection), y = variable, fill = value_cat)) +
  geom_tile(color = 'grey50') +
  xlab('Detection') +
  ylab('Parameter') +
  facet_nested(samp_size + N ~ survey_frequency + survey_freq + length, drop = T,
             labeller = labeller(survey_freq = freq_labels),
             scales = 'free_x') +
  theme_bw() +
  theme(legend.position = 'top',
             strip.background = element_rect(fill = "#EEEEEE", color = "#FFFFFF")) +
    scale_y_discrete("", labels = parse(text = c(eval(expression(levels(plot_dat$variable)))))) +
  scale_fill_manual(name = "Probability of detecting change in survival",
                    values = c('firebrick3', 'orange', 'steelblue2'))

#dot plots
dotplot_dat <- cri.all %>%
  merge(scenarios, by = 'scenario', all = F) %>%
  group_by(threshold, length, variable, detection, survey_freq, N) %>%
  # dplyr::summarize(value = mean(value),
  #                  lower = quantile(value, probs = 0.025),
  #                  upper = quantile(value, probs = 0.975),
    dplyr::summarize(value = mean(value), .groups = 'keep') %>%
  transform(variable = factor(variable, levels = c('phiP', 'phi1', 'phi2', 'phiJ', 'phiA'))) %>%
  transform(detection = factor(detection, levels = c('Low', 'Med', 'High'))) %>%
  transform(survey_frequency = 'Survey frequency', samp_size = 'Sample size') %>%
  transform(threshold = factor(threshold, levels = c('dec_little', 'dec_big', 'inc_little', 'inc_big'),
                               labels = c('Small decrease', 'Big decrease', 'Small increase', 'Big increase')))


ggplot(plot_dat %>% filter(threshold %in% c('Small decrease', 'Big decrease')),
       aes(x = N, y = value, col = length, group = length)) +
  geom_point() + geom_line() +
  geom_hline(aes(yintercept = 0), linetype = 'dotted') +
  xlab('Sample size') + ylab('Probability of detecting change') +
    # facet_grid(variable~adult_p, labeller = labeller(variable = 'label_parsed'), scales = 'free') +
  facet_grid(variable + detection ~ survey_freq + threshold, label = 'label_parsed', scales = 'free') +
  theme_bw() +
  plot_theme(legend.position = 'top',
             plot.subtitle = element_text(size = 10, hjust = 0.5, vjust = 1)) +
  scale_color_manual(values = rainbow2[c(5,2)], name = 'Threshold')



```

